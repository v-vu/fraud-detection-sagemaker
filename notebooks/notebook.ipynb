{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Tabular Data ML Project Using SageMaker Studio and the Amazon SageMaker Python SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "\n",
    "This basic setup code has been included to help you get started. Read and run these cells first to get packages installed and variables created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U shap\n",
    "%pip install -U smdebug\n",
    "%pip install imbalanced-learn\n",
    "%pip install pytest-cov\n",
    "%pip install pytest-filter-subpackage\n",
    "%pip install sagemaker\n",
    "%pip install -U seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required-libraries\n",
    "\n",
    "import boto3\n",
    "import datetime as datetime\n",
    "import io\n",
    "import IPython\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt  # visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import re\n",
    "import sagemaker\n",
    "import seaborn as sns  # visualization\n",
    "import statistics\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sagemaker import clarify\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from sagemaker.dataset_definition.inputs import AthenaDatasetDefinition, DatasetDefinition, RedshiftDatasetDefinition\n",
    "from sagemaker.debugger import CollectionConfig, DebuggerHookConfig, FrameworkProfile, ProfilerConfig, ProfilerRule, Rule, rule_configs\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.experiments.run import Run, load_run\n",
    "from sagemaker.feature_store.feature_definition import FeatureDefinition\n",
    "from sagemaker.feature_store.feature_definition import FeatureTypeEnum\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.network import NetworkConfig\n",
    "from sagemaker.processing import FeatureStoreOutput\n",
    "from sagemaker.processing import Processor, ProcessingInput, ProcessingOutput, ScriptProcessor\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.workflow.condition_step import ConditionStep, JsonGet\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThan\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterFloat, ParameterString\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic-variable-code-and-settings\n",
    "\n",
    "%matplotlib inline\n",
    "base_job_name = \"capstone-smdebugger-job\"\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "bucket_path = \"s3://{}\".format(bucket)\n",
    "prefix = \"sagemaker/capstone\"\n",
    "region = boto3.Session().region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "s3_client = boto3.client(\"s3\") \n",
    "sagemaker_session = sagemaker.Session() \n",
    "save_interval = 5\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset description\n",
    "\n",
    "Five tables are stored in an Amazon Simple Storage Service (Amazon S3) bucket:\n",
    "- **claims.csv**: A table with raw claims data.\n",
    "- **customers.csv**: A table with raw customer data.\n",
    "- **claims_preprocessed.csv**: A table with processed claims data.\n",
    "- **customers_preprocessed.csv**: A table with processed customer data.\n",
    "- **claims_customer.csv**: A table joined on the **policy_id** of the processed claims and customer data.\n",
    "\n",
    "For this lab, start with the **claims.csv** and **customers.csv** tables. You process them in **Challenge 1** using Amazon SageMaker Data Wrangler. If you get stuck, or want a reference of what the processed dataset should be, you can review the pre-processed tables.\n",
    "\n",
    "For this dataset, the target is **fraud**, a column in the claims table.\n",
    "\n",
    "The claims table includes the following fields: \n",
    "\n",
    "- **policy_id**: The unique ID for the policy.\n",
    "- **driver_relationship**: A list of relationships (Spouse, Self, Child, Other, N/A).\n",
    "- **incident_type**: The incident type reported (Break-In, Collision, Theft).\n",
    "- **collision_type**: The location of the collision (Front, Rear, Side, N/A).\n",
    "- **incident_severity**: The severity of the incident (Minor, Major, Totaled).\n",
    "- **authorities_contacted**: The type of authorities first contacted (None, Police, Ambulance, Fire).\n",
    "- **num_vehicles_involved**: The number of vehicles involved in the incident (a range from 1 to 6).\n",
    "- **num_injuries**: The number of injuries involved in the incident (a range from 1 to 4).\n",
    "- **num_witnesses**: The number of witnesses to the incident (a range from 1 to 5).\n",
    "- **police_report_available**: Whether or not a police report is available (yes or no).\n",
    "- **injury_claim**: The value claimed for injuries in US dollars (300 to 576,300 USD).\n",
    "- **vehicle_claim**: The value claimed for vehicle damage in US dollars (1000 to 51,051 USD).\n",
    "- **total_claim_amount**: The total value claimed for injuries and damages (2100 to 588,868 USD).\n",
    "- **incident_month**: The month of the incident (a range from 1 to 12).\n",
    "- **incident_day**: The day of the incident (a range from 1 to 31).\n",
    "- **incident_dow**: The day of the week of the incident (a range from 0 to 6 representing Sunday to Saturday).\n",
    "- **incident_hour**: The hour of the incident (a range from 0 to 23)\n",
    "- **fraud**: Whether or not the policy was fraudulent (0 or 1).\n",
    "\n",
    "The customers table includes the following fields:\n",
    "\n",
    "- **policy_id**: The unique ID for the policy.\n",
    "- **customer_age**: The age of the customer (a range from 18 to 70).\n",
    "- **months_as_customer**: The number of months for which this customer has paid insurance (a range from 1 to 495).\n",
    "- **num_claims_past_year**: The number of claims made by the customer in the past year.\n",
    "- **num_insurers_past_5_years**: The number of insurers that the customer had in the past 5 years.\n",
    "- **policy_state**: The state that the customer lives in (AZ, CA, ID, NV, OR, WA).\n",
    "- **policy_deductable**: The deductable value of the policy in US dollars (a range from 750 to 1100 USD).\n",
    "- **policy_annual_premium**: The annual premium of the policy in US dollars (a range from 2200 to 3000 USD).\n",
    "- **policy_liability**: The liability maximums for bodily injury, split into single and all bodily injuries (15/30, 25/50, 60/90, 100/200).\n",
    "- **customer_zip**: The zip code of the customer (a range from 83201 to 99362).\n",
    "- **customer_gender**: The gender of the customer (Male, Female, Other, Unknown).\n",
    "- **customer_education**: The education level of the customer (Below High School, High School, Associate, Bachelor, Advanced Degree).\n",
    "- **auto_year**: The year in which the automobile was made (a range from 2001 to 2020).\n",
    "\n",
    "You can join these tables with an inner join on the **policy_id** column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge lab navigation\n",
    "\n",
    "This lab is set up with links that navigate between the challenge tasks and the appendix at the end of the notebook. If you want to review an item in the appendix, choose the associated hyperlink. When you want to return to the challenge that you are currently working on, choose the corresponding task hyperlink in the appendix.\n",
    "\n",
    "The lab is organized as follows:\n",
    "\n",
    "- Challenge 1: Analyze and prepare the dataset with SageMaker Data Wrangler\n",
    "- Challenge 2: Create feature groups in SageMaker Feature Store\n",
    "- Challenge 3: Train the model\n",
    "- Challenge 4: Evaluate the model for bias\n",
    "- Challenge 5: Batch transform\n",
    "- Challenge 6: Build an automated pipeline\n",
    "- Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1: Analyze and prepare the dataset with SageMaker Data Wrangler\n",
    "\n",
    "AnyCompany Consulting has received a request to analyze auto insurance fraud datasets and build a model to help predict if new claims are likely to be fraudulent or not. It has 5,000 customer records where it has labeled each claim as fraudulent or not. You can use this data to train, test, and validate your model before running inference on a new batch collection of records.\n",
    "\n",
    "Use analysis features of Amazon SageMaker Data Wrangler to visualize the distributions of data in important columns, check for correlation between columns, and check for target leakage. Next, build a quick baseline model. Then, use data processing features of SageMaker Data Wrangler to transform columns so that they are better suited for training a more performant model. \n",
    "\n",
    "To complete this task, you complete the following subtasks:\n",
    "\n",
    "- Review your data.\n",
    "- Complete an exploratory data analysis in Amazon SageMaker Studio.\n",
    "- Use an Amazon SageMaker Clarify processor job to run a bias report.\n",
    "- Prepare your data.\n",
    "\n",
    "This challenge takes approximately *100* minutes to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1: Review your data\n",
    "\n",
    "<a id=\"task1-1-continue\"></a>\n",
    "\n",
    "Access the tabular auto insurance dataset stored in your repository and review a sample of the dataset. The repository contains two unprocessed tables. One for customer data named **customers.csv** and one for claims data named **claims.csv**.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> The unprocessed tables are located in the **./data/** folder.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> The **claims.csv** and **customers.csv** tables are the unprocessed tables.\n",
    "\n",
    "Take a moment to explore the tables. Are there any fields that stand out? Are there any fields that require careful preprocessing?\n",
    "\n",
    "For detailed steps how to review your data, refer to <a href=\"#task1-1\" target=\"_self\">**Review your data (Task 1.1)**</a> in the *Appendix* section.\n",
    "\n",
    "After you access the auto insurance fraud table and review a sample of the dataset, you have completed this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_1_1_code_here\n",
    "claims = pd.read_csv('data/claims.csv')\n",
    "\n",
    "customers = pd.read_csv('data/customers.csv')\n",
    "claims.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2: Complete an exploratory data analysis in SageMaker Studio \n",
    "\n",
    "<a id=\"task1-2-continue\"></a>\n",
    "\n",
    "Complete an exploratory data analysis by reviewing the data, identifying potential issues in the dataset, and checking for strong correlations between any columns and the target. You can explore the data in SageMaker Data Wrangler and in the notebook.\n",
    "\n",
    "Specifically, spend time reviewing the following items:\n",
    "- **Column histograms**: Review the columns in a visual format and check what kinds of values are in the dataset.\n",
    "- **Quick model**: Review the dataset and think about an expected model outcome.\n",
    "- **Feature correlation**: Check if there is strong correlation between any columns and the target.\n",
    "- **Target leakage**: Check if there is any data that is dependent on the target value.\n",
    "\n",
    "Access SageMaker Data Wrangler using SageMaker Canvas. To follow these directions, use one of the following options:\n",
    "- **Option 1:** Open a new browser window for SageMaker Data Wrangler. Arrange the new window and the window displaying JupyterLab side-by-side. You can now have the directions visible as you explore the feature group.\n",
    "- **Option 2:** Open a new browser tab in the existing browser window for SageMaker Data Wrangler. Switch between the browser tabs to follow these instructions.\n",
    "\n",
    "If you get a **\"The following instance type is not available: ml.m5.4xlarge. Try selecting a different instance below.\"** error when creating a new flow file, you can choose another instance type. Try the **ml.m5.8xlarge** next.\n",
    "\n",
    "If the message **An error occurred loading this view** displays, close the **untitled.flow** tab and reopen the flow file from the file browser.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> There are many ways to explore the dataset. Open a SageMaker Data Wrangler flow to get started. You need both the **claims.csv** and **customers.csv** imported into SageMaker Data Wrangler from the S3 bucket that contains **databucket-** in its name.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> To import a second table, return to your **Data flow**, then choose the **Add data** tab to import another dataset.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> **Get data insights** is a way to explore data in SageMaker Data Wrangler. After you review some sample charts from your data, you can use other plotting tools in the notebook to analyze the data if you want to. The **plt** and **sns** libraries have been installed. Feel free to use any analysis tools that you are familiar with to explore the dataset.  \n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Try joining the two tables using a **Join** on **policy_id**. Then, run another insights report. You can use an **Inner** join for these tables.\n",
    "\n",
    "Did you get more meaningful results with a joined dataset?\n",
    "\n",
    "For detailed steps to explore a dataset in SageMaker Canvas, refer to <a href=\"#task1-2-1\" target=\"_self\">**Explore a dataset in SageMaker Studio (Task 1.2)**</a> in the *Appendix* section.\n",
    "\n",
    "For detailed steps to explore a dataset in the notebook, refer to <a href=\"#task1-2-2\" target=\"_self\">**Explore a dataset in the notebook (Task 1.2)**</a> in the *Appendix* section.\n",
    "\n",
    "After you have processed the data using SageMaker Data Wrangler, explored the dataset and identified the processing steps that you want to conduct, you have completed this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_1_2_code_here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3: Use a SageMaker Clarify processor job to run a bias report\n",
    "\n",
    "<a id=\"task1-3-continue\"></a>\n",
    "\n",
    "Use SageMaker Clarify to run a pre-training bias report to catch class imbalance in the data. Use a SageMaker Data Wrangler flow to run the bias report in SageMaker Studio.\n",
    "1. Start with joining the two tables.\n",
    "\n",
    "- Join: **Inner** join for **claims.csv** to **customers.csv** on **policy_id**.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> To create a pre-training bias report, add a new analysis to your SageMaker Data Wrangler flow and choose **Bias Report** for the **Analysis type**.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> You can run the bias report several times, choosing different features to analyze each time.\n",
    "\n",
    "For detailed steps how to join tables with SageMaker Data Wrangler, refer to <a href=\"#task1-3-1\" target=\"_self\">**Joining tables in SageMaker Studio (Task 1.3)**</a> in the *Appendix* section.\n",
    "\n",
    "For detailed steps how to run a pre-training bias report, refer to <a href=\"#task1-3-2\" target=\"_self\">**Run a pre-training bias report (Task 1.3)**</a> in the *Appendix* section.\n",
    "\n",
    "After you have run the pre-training bias report and viewed the report, you have completed this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.4: Prepare your data\n",
    "\n",
    "<a id=\"task1-4-continue\"></a>\n",
    "\n",
    "Prepare your dataset using SageMaker Data Wrangler. Focus on the following transformations, but feel free to include other transformations:\n",
    "\n",
    "- Encode categorical (One-hot encoding): **authorities_contacted**, **collision_type**, **customer_gender**, **driver_relationship**, **incident_type**, and **policy_state**.\n",
    "- Ordinal encode: **customer_education**, **policy_liability**, **incident_severity**, and **police_report_available**.\n",
    "- Parse column as type: **vehicle_claim** and **total_claim_amount** from **Float** to **Long**.\n",
    "- Manage columns (Drop column): **customer_zip**.\n",
    "- Manage columns (Move column): **fraud** (using **Move to start**).\n",
    "- Manage columns (Rename column): Remove the **/** symbol from **collision_type_N/A**, and **driver_relationship_N/A** with a **_**.\n",
    "- Manage columns (Rename column): Rename **policy_id_0** to **policy_id**.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Join the **claims** table to the **customers** tables using a join in SageMaker Data Wrangler. \n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Join the two tables on the **policy_id** column.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Add transformations using the **Add transform** option.\n",
    "\n",
    "Which transformations do you think affects the model training the most?\n",
    "\n",
    "For detailed steps how to prepare data using SageMaker Data Wrangler, refer to <a href=\"#task1-4-1\" target=\"_self\">**Prepare data using SageMaker Data Wrangler (Task 1.4)**</a> in the *Appendix* section.\n",
    "\n",
    "If you want to import an example set of processed data, refer to <a href=\"#task1-4-2\" target=\"_self\">**Import an example set of processed data (Task 1.4)**</a> in the *Appendix* section. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2: Create feature groups in SageMaker Feature Store\n",
    "\n",
    "Now that you have processed the dataset, create features and feature groups to be used in future analysis. Use SageMaker Feature Store to store these in a feature group and query them when training your model.\n",
    "\n",
    "To complete this task, complete all of the following subtasks:\n",
    "\n",
    "1. Export features to SageMaker Feature Store.\n",
    "2. Query the feature group in an offline store with Amazon Athena.\n",
    "\n",
    "This challenge takes approximately *30* minutes to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1: Export features to SageMaker Feature Store\n",
    "\n",
    "<a id=\"task2-1-continue\"></a>\n",
    "\n",
    "Use the SageMaker Data Wrangler **Export to** feature to create a custom Jupyter Notebook. The notebook creates a feature definition and a feature group. The notebook ingests the records into the feature group. In the notebook, complete the following steps:\n",
    "\n",
    "- Set the values for record and event_time.\n",
    "- Update the **container_uri** variable value:\n",
    "\n",
    "    <i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> If you are running the lab in the **us-east-1** region, replace the current value with: `663277389841.dkr.ecr.us-east-1.amazonaws.com/sagemaker-data-wrangler-container:2.x`\n",
    "\n",
    "    <i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> If you are running the lab in the **us-west-2** region, replace the current value with: `174368400705.dkr.ecr.us-west-2.amazonaws.com/sagemaker-data-wrangler-container:2.x`\n",
    "\n",
    "- Run the notebook cells to create the feature group.\n",
    "- Run the notebook cells to confirm the created feature group.\n",
    "- Run the notebook cells to ingest records into the feature group.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> You will complete the initial steps for this task in SageMaker Data Wrangler. Then, you will complete the rest of the steps using the exported notebook. You will upload the exported notebook to JupyterLab to update and run the generated code. When you have finished creating your feature group, you can return to this notebook to continue with Task 2.2.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Add a custom transformation to create the **event_time** column. \n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> The code to add the custom transformation is as follows:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import lit\n",
    "date_time = datetime.date.today()\n",
    "\n",
    "df = df.withColumn(\"event_time\", lit(time.mktime(date_time.timetuple())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> At the end of your SageMaker Data Wrangler flow, choose the **+** icon, choose the **Export via Jupyter Notebook** option, and choose **SageMaker Feature Store**.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> You can turn off the online store by changing the **enable_online_store** value from **True** to **False**.\n",
    "\n",
    "How would you use SageMaker Feature Store to store and query your records for training, as opposed to inference?\n",
    "\n",
    "For detailed steps how to create a feature group using the **Export to** option, refer to <a href=\"#task2-1\" target=\"_self\">**Create a feature group using the Export to option (Task 2.1)**</a> in the *Appendix* section. \n",
    "\n",
    "After you have created a feature group and ingested data into the feature group, you have completed this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2: Query the feature group in an offline store with Athena\n",
    "\n",
    "<a id=\"task2-2-continue\"></a>\n",
    "\n",
    "Use Athena to extract records from an offline data store. You split these records into train, test, and validation sets in the next challenge.\n",
    "\n",
    "Use the provided code cell below to make the Amazon Athena API calls. You could use the Amazon Athena console to make the query, but that is beyond the scope of this lab.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> You can create an Athena query with **feature_group.athena_query()** and get the table name with **query.table_name**.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> You can run a query with **query.run(query_string=query_string, output_location=output_location)** and read the returned value as a dataframe with **query.as_dataframe()**.\n",
    "\n",
    "How could you use **event_time** to keep track of features that occur at different points in your dataset's timeline?\n",
    "\n",
    "For detailed steps how to extract records from an offline data store with Athena, refer to <a href=\"#task2-2\" target=\"_self\">**Extract records from an offline store with Athena (Task 2.2)**</a> in the *Appendix* section.\n",
    "\n",
    "After you have saved the returned Athena query as a dataframe variable, you have completed this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_2_2_code_here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3: Train the model\n",
    "\n",
    "Your model is ready to train. Split the data into train, test, and validation datasets, and train the model. \n",
    "\n",
    "SageMaker Autopilot was run on this data earlier and got a **F1** of **0.616**, an **accuracy** of **0.978**, an **AUC** of **0.918**, and a **Recall** of **0.539**. To learn more about the metrics that SageMaker Autopilot produces, refer to the *autopilot-metrics-validation* document in the *Additional resources* section for more information.\n",
    "\n",
    "While you are training and tuning, work on reaching or exceeding the SageMaker Autopilot scores and confirm that Amazon SageMaker Debugger is reporting no errors.\n",
    "\n",
    "To complete this task, you complete the following subtasks:\n",
    "\n",
    "- Create an experiment and a run.\n",
    "- Split the data into train, test, and validation datasets.\n",
    "- Configure and run a training job.\n",
    "    - Run a basic training job.\n",
    "    - Run a training job with SageMaker Debugger enabled and analyze the reports (optional).\n",
    "- Perform hyperparameter tuning.\n",
    "\n",
    "This challenge takes approximately *110* minutes to complete.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1: Name an experiment and a run\n",
    "\n",
    "<a id=\"task3-1-continue\"></a>\n",
    "\n",
    "Set up variables to name both the experiment and the runs. \n",
    "An experiment requires an **experiment_name**, **run_name** and a **description**. \n",
    "\n",
    "For detailed steps how to create the variables, refer to <a href=\"#task3-1\" target=\"_self\">**Name an experiment and a run (Task 3.1)**</a> in the *Appendix* section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "#add_your_task_3_1_code_here\n",
    "create_date = strftime(\"%m%d%H%M\")\n",
    "\n",
    "experiment_name = \"capstone\".format(create_date)\n",
    "description = \"Using SageMaker Experiments - Capstone.\"\n",
    "\n",
    "# create initial run_name\n",
    "run_name = \"capstone-run-{}\".format(create_date)\n",
    "\n",
    "# define a run_tag\n",
    "run_tags = [{'Key': 'capstone', 'Value': 'capstone-run'}]\n",
    "\n",
    "print(f\"Experiment name - {experiment_name},  run name - {run_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2: Split the data into train, test, and validation datasets\n",
    "\n",
    "<a id=\"task3-2-continue\"></a>\n",
    "\n",
    "Use the features that you queried from SageMaker Feature Store and split the data into train, test, and validation datasets.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Use **np.split** to split the dataset into three partitions.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Use the **to_csv** to create CSV files and use **S3Uploader.upload** to add the files to Amazon S3.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> The final product of your split should be a **data_inputs** variable with values for **train** and **validation**.\n",
    "\n",
    "For detailed steps how to split data into train, test, and validation datasets, refer to <a href=\"#task3-2\" target=\"_self\">**Split data into train, test, and validation datasets (Task 3.2)**</a> in the *Appendix* section. \n",
    "\n",
    "After you have split the data into train, test, and validation datasets, you have completed this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_3_2_code_here\n",
    "#import-dataset\n",
    "lab_test_data = pd.read_csv('data/claims_customer.csv')\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "lab_test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split-dataset\n",
    "train_data, validation_data, test_data = np.split(\n",
    "    lab_test_data.sample(frac=1, random_state=1729),\n",
    "    [int(0.7 * len(lab_test_data)), int(0.9 * len(lab_test_data))],\n",
    ")\n",
    "\n",
    "train_data.to_csv('train_data.csv', index=False, header=False)\n",
    "validation_data.to_csv('validation_data.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload-dataset\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "train_path = S3Uploader.upload('train_data.csv', 's3://{}/{}'.format(bucket, prefix))\n",
    "validation_path = S3Uploader.upload('validation_data.csv', 's3://{}/{}'.format(bucket, prefix))\n",
    "\n",
    "train_input = TrainingInput(train_path, content_type='text/csv')\n",
    "validation_input = TrainingInput(validation_path, content_type='text/csv')\n",
    "\n",
    "data_inputs = {\n",
    "    'train': train_input,\n",
    "    'validation': validation_input\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.3: Configure and run a training job\n",
    "\n",
    "<a id=\"task3-3-continue\"></a>\n",
    "\n",
    "Start your first training job, setting up the container, an estimator, and the hyperparameters. Then, train the model with **fit()**. If you want to examine more detailed reports, enable SageMaker Debugger with **DebuggerHookConfig**.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Use the **XGBoost** container with version **1.5-1**.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> To get started, set the hyperparameters for **eta**, **gamma**, **max_depth**, **min_child_weight**, **num_round**, **objective**, and **subsample**.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Use the **data_inputs** that you created earlier in Challenge 1 as the **inputs** value for your training job.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> You can configure a training job by setting the inputs and experiment_config. The experiment_config should contain a **sagemaker_session**, a **run_name**, and a **experiment_name**.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> If you want to use SageMaker Debugger, configure the **DebuggerHookConfig**, the **ProfilerConfig**, and the Debugger **rule** object.\n",
    "\n",
    "Which hyperparameters are most likely to have a large impact on your model's performance and accuracy? Which hyperparameters do you plan on tuning first?\n",
    "\n",
    "For detailed steps how to configure and run a basic training job, refer to <a href=\"#task3-3-1\" target=\"_self\">**Configure and run a basic training job (Task 3.3)**</a> in the *Appendix* section.\n",
    "\n",
    "For detailed steps how to configure and run a training job with Debugger enabled and analyze reports, refer to <a href=\"#task3-3-2\" target=\"_self\">**Configure and run a training job with SageMaker Debugger enabled and analyze reports (Task 3.3)**</a> in the *Appendix* section.\n",
    "\n",
    "After you have finished one or more training jobs, you have completed this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_3_3_code_here\n",
    "from sagemaker import image_uris\n",
    "container = image_uris.retrieve(framework='xgboost',region=boto3.Session().region_name,version='1.5-1')\n",
    "\n",
    "# initialize hyperparameters\n",
    "eta=0.2\n",
    "gamma=4\n",
    "max_depth=5\n",
    "min_child_weight=6\n",
    "num_round=800\n",
    "objective='binary:logistic'\n",
    "subsample=0.8\n",
    "verbosity=0\n",
    "\n",
    "hyperparameters = {\n",
    "        \"max_depth\":max_depth,\n",
    "        \"eta\":eta,\n",
    "        \"gamma\":gamma,\n",
    "        \"min_child_weight\":min_child_weight,\n",
    "        \"subsample\":subsample,\n",
    "        \"verbosity\":verbosity,\n",
    "        \"objective\":objective,\n",
    "        \"num_round\":num_round\n",
    "}\n",
    "\n",
    "# Set up the estimator\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role, \n",
    "    instance_count=1, \n",
    "    instance_type='ml.m5.xlarge',\n",
    "    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    EnableSageMakerMetricsTimeSeries=True,\n",
    "    hyperparameters=hyperparameters,\n",
    "    tags = run_tags\n",
    ")\n",
    "\n",
    "\n",
    "#Run the training job link to Experiment.\n",
    "with Run(\n",
    "    experiment_name=experiment_name,\n",
    "    run_name=run_name,\n",
    "    tags=run_tags,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "\n",
    "    run.log_parameters({\n",
    "                        \"eta\": eta, \n",
    "                        \"gamma\": gamma, \n",
    "                        \"max_depth\": max_depth,\n",
    "                        \"min_child_weight\": min_child_weight,\n",
    "                        \"num_round\": num_round,\n",
    "                        \"objective\": objective,\n",
    "                        \"subsample\": subsample,\n",
    "                        \"verbosity\": verbosity\n",
    "                       })\n",
    "    \n",
    "#    you may also specify metrics to log\n",
    "#    run.log_metric(name=\"\", value=x)\n",
    "\n",
    "# Train the model associating the training run with the current \"experiment\"\n",
    "    xgb.fit(\n",
    "        inputs = data_inputs\n",
    "    ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize-training-results-table\n",
    "run_component_analytics = ExperimentAnalytics(\n",
    "    experiment_name=experiment_name,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "run_component_analytics.dataframe()[\"validation:logloss - Last\"].plot(kind=\"bar\", title=\"validation:logloss - Last\", xlabel=\"training job\", ylabel=\"logloss_max\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = run_component_analytics.dataframe()\n",
    "\n",
    "# Check available columns\n",
    "print(df.columns)\n",
    "\n",
    "# Plot if the column exists\n",
    "if \"validation:logloss - Last\" in df.columns:\n",
    "    df[\"validation:logloss - Last\"].plot(\n",
    "        kind=\"bar\",\n",
    "        title=\"Validation LogLoss (Last)\",\n",
    "        xlabel=\"Training Job\",\n",
    "        ylabel=\"LogLoss\"\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Column 'validation:logloss - Last' not found in experiment analytics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.4: Hyperparameter tuning\n",
    "\n",
    "<a id=\"task3-4-continue\"></a>\n",
    "\n",
    "Now that you have finished a training job and analyzed it, tune hyperparameter ranges based on your findings and run more training jobs to improve the model.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> To get started, set the hyperparameter ranges for **alpha**, **eta**, **max_depth**, **min_child_weight**, and **num_round**.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> When you run **HyperparameterTuner**, make sure to set the **objective_metric_name** and **objective_type** based on your findings.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> To check if you have improved over the SageMaker Autopilot results, open the **Experiments and runs** menu in **SageMaker resources**. In your run, view the **Metrics**. The **ObjectiveMetric** should be higher than the **F1** score of **0.616** and the **validation:auc** should have a **Final value** higher than the SageMaker Autopilot score of **0.918**.\n",
    "\n",
    "When you tuned your hyperparameters, which one caused the greatest improvement in model performance?\n",
    "\n",
    "For detailed steps how to configure training hyperparameter ranges, refer to <a href=\"#task3-4\" target=\"_self\">**Configure training hyperparameter ranges (Task 3.4)**</a> in the *Appendix* section.\n",
    "\n",
    "After you have configured the training hyperparameter ranges and started more training jobs, you have completed this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_3_4_code_here\n",
    "#tune-model\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "# Setup the hyperparameter ranges\n",
    "hyperparameter_ranges = {\n",
    "    'alpha': ContinuousParameter(0, 2),\n",
    "    'eta': ContinuousParameter(0, 1),\n",
    "    'max_depth': IntegerParameter(1, 10),\n",
    "    'min_child_weight': ContinuousParameter(1, 10),\n",
    "    'num_round': IntegerParameter(100, 1000)\n",
    "}\n",
    "# Define the target metric and the objective type (max/min)\n",
    "objective_metric_name = 'validation:auc'\n",
    "objective_type='Maximize'\n",
    "# Define the HyperparameterTuner\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator = xgb,\n",
    "    objective_metric_name = objective_metric_name,\n",
    "    hyperparameter_ranges = hyperparameter_ranges,\n",
    "    objective_type = objective_type,\n",
    "    max_jobs=12,\n",
    "    max_parallel_jobs=4,\n",
    "    early_stopping_type='Auto',\n",
    ")\n",
    "\n",
    "with load_run(sagemaker_session=sagemaker_session, experiment_name=experiment_name, run_name=run_name) as run:\n",
    "# Tune the model\n",
    "    tuner.fit(\n",
    "        inputs = data_inputs,\n",
    "        job_name = experiment_name,\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_experiment_analytics \n",
    "run_component_analytics = ExperimentAnalytics(\n",
    "    experiment_name=experiment_name+\"-aws-tuning-job\",\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "run_component_analytics.dataframe()\n",
    "\n",
    "#visualize-tuning-results-auc-max\n",
    "if run_component_analytics.dataframe()[\"validation:auc - Max\"].iloc[1] != 0:\n",
    "    run_component_analytics.dataframe()[\"validation:auc - Max\"].plot(kind=\"bar\", title=\"validation:auc - Max\", xlabel=\"training job\", ylabel=\"auc_max\").set_ylim([0.8, 1]);\n",
    "else:\n",
    "    run_component_analytics.dataframe()[\"validation:auc - Last\"].plot(kind=\"bar\", title=\"validation:auc - Last\", xlabel=\"training job\", ylabel=\"auc_max\").set_ylim([0.8, 1]);\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize-tuning-results-auc-max-scatter\n",
    "N = 12\n",
    "if run_component_analytics.dataframe()[\"validation:auc - Max\"].iloc[1] != 0:\n",
    "    x = run_component_analytics.dataframe().sort_values(by=['TrialComponentName'])[\"validation:auc - Max\"];\n",
    "else:\n",
    "    x = run_component_analytics.dataframe().sort_values(by=['TrialComponentName'])[\"validation:auc - Last\"];\n",
    "y = run_component_analytics.dataframe().sort_values(by=['TrialComponentName'])[\"num_round\"]\n",
    "\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "plt.title(\"auc_max by num_round\")\n",
    "plt.xlabel(\"validation:auc - Max\")\n",
    "plt.ylabel(\"num_round\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print-best\n",
    "tuner.best_training_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 4: Evaluate the model for bias\n",
    "\n",
    "Now that your model is trained, evaluate your model using Amazon SageMaker Clarify. If you find any issues, you can remove the imbalance detected and retrain the model.\n",
    "\n",
    "To complete this task, you complete the following subtasks:\n",
    "\n",
    "- Create a model from the training job.\n",
    "- Create a SageMaker Clarify model configuration.\n",
    "- Create a SageMaker Clarify bias configuration.\n",
    "- Use a SageMaker Clarify processor job to run the bias, data, and model reports.\n",
    "- Remove the imbalance detected with SageMaker Clarify (optional).\n",
    "- Retrain the model (optional).\n",
    "\n",
    "This challenge takes approximately *80* minutes to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.1: Create a model from the training job\n",
    "\n",
    "<a id=\"task4-1-continue\"></a>\n",
    "\n",
    "Create an XGBoost model, calling **create_model** with the **model_name**, **role**, and **container_def** that you define.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Call **xgb.create_model()** and pick a name for your model.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Use your session and call **create_model**, passing in the **model_name**, **role**, and **container_def**.\n",
    "\n",
    "For detailed steps how to create a model, refer to <a href=\"#task4-1\" target=\"_self\">**Create a model (Task 4.1)**</a> in the *Appendix* section.\n",
    "\n",
    "After you have created a model, you have completed this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_4_1_code_here\n",
    "model_name = \"capstone-clarify-model\"\n",
    "model = xgb.create_model(name=model_name)\n",
    "container_def = model.prepare_container_def()\n",
    "sagemaker_session.create_model(model_name, role, container_def)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.2: Create a SageMaker Clarify model configuration\n",
    "\n",
    "<a id=\"task4-2-continue\"></a>\n",
    "\n",
    "Create a SageMaker Clarify model configuration using **SageMakerClarifyProcessor**.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Set the **instance_count** and the **instance_type**.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Use the **role** and **session** created at the beginning of the Capstone lab.\n",
    "\n",
    "For detailed steps how to create a SageMaker Clarify model configuration, refer to <a href=\"#task4-2\" target=\"_self\">**Create a SageMaker Clarify model configuration (Task 4.2)**</a> in the *Appendix* section.\n",
    "\n",
    "After you have created a SageMaker Clarify model configuration, you have completed this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_4_2_code_here\n",
    "#enable-clarify\n",
    "\n",
    "clarify_processor = clarify.SageMakerClarifyProcessor(\n",
    "    role=role, \n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.m5.xlarge\", \n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.3: Create a SageMaker Clarify bias configuration\n",
    "\n",
    "<a id=\"task4-3-continue\"></a>\n",
    "\n",
    "Create a data configuration, a model configuration, a label configuration, and a bias configuration.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Start with a **DataConfig**, setting the input path, output path, headers, and dataset type.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Then, create a **ModelConfig**, choosing the content and accept type, the model name, the instance type, and the instance count.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Next, create a **ModelPredictedLabelConfig**, setting the probability threshold.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Finally, create a **BiasConfig**, setting the label values or threshold, the facet name, and the facet values or threshold.\n",
    "\n",
    "Which facets do you want to explore first in your bias report? Are there any features that are particularly susceptible to bias?\n",
    "\n",
    "For detailed steps how to create a SageMaker Clarify bias configuration, refer to <a href=\"#task4-3\" target=\"_self\">**Create a SageMaker Clarify bias configuration (Task 4.3)**</a> in the *Appendix* section.\n",
    "\n",
    "After you have created a SageMaker Clarify bias configuration, you have completed this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_4_3_code_here\n",
    "\n",
    "bias_report_output_path = \"s3://{}/{}/clarify-bias\".format(bucket, prefix)\n",
    "bias_data_config = clarify.DataConfig(\n",
    "    s3_data_input_path=train_path,\n",
    "    s3_output_path=bias_report_output_path,\n",
    "    label=\"fraud\",\n",
    "    headers=train_data.columns.to_list(),\n",
    "    dataset_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "#define-model-config\n",
    "\n",
    "model_config = clarify.ModelConfig(\n",
    "    model_name=model_name,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    accept_type=\"text/csv\",\n",
    "    content_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "#define-model-predicted-label-config\n",
    "\n",
    "predictions_config = clarify.ModelPredictedLabelConfig(probability_threshold=0.8)\n",
    "\n",
    "#define-bias-config\n",
    "\n",
    "bias_config = clarify.BiasConfig(\n",
    "    label_values_or_threshold=[1], facet_name=\"customer_gender_female\", facet_values_or_threshold=[0], group_name=\"customer_age\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.4: Use a SageMaker Clarify processor job to run the bias, data, and model reports\n",
    "\n",
    "<a id=\"task4-4-continue\"></a>\n",
    "\n",
    "You chose all your configurations already for the bias, data, and model reports. Now, run the reports.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Pass the **data_config**, **bias_config**, **model_predicted_label_config**, and **model_config** values to **run_bias**.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> You need to set the **pre_training_methods** and **post_training_methods**.\n",
    "\n",
    "For detailed steps how to run bias, data, and model reports using SageMaker Clarify, refer to <a href=\"#task4-4\" target=\"_self\">**Run bias, data, and model reports using SageMaker Clarify (Task 4.4)**</a> in the *Appendix* section.\n",
    "\n",
    "After you have used a SageMaker Clarify processor job to run the bias, data, and model reports, you have completed this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_4_4_code_here\n",
    "#run-bias-report\n",
    "\n",
    "clarify_processor.run_bias(\n",
    "    data_config=bias_data_config,\n",
    "    bias_config=bias_config,\n",
    "    model_config=model_config,\n",
    "    model_predicted_label_config=predictions_config,\n",
    "    pre_training_methods=\"all\",\n",
    "    post_training_methods=\"all\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-shap\n",
    "\n",
    "testing_data, clarify_data = train_test_split(test_data, test_size =0.005)\n",
    "clarify_data = clarify_data.drop(columns=[\"fraud\"])\n",
    "clarify_data.to_csv('clarify_data.csv', index=False, header=False)\n",
    "clarify_path = S3Uploader.upload('clarify_data.csv', 's3://{}/{}'.format(bucket, prefix))\n",
    "\n",
    "shap_config = clarify.SHAPConfig(\n",
    "    baseline=clarify_path,\n",
    "    num_samples=15,\n",
    "    agg_method=\"mean_abs\",\n",
    "    save_local_shap_values=True,\n",
    ")\n",
    "\n",
    "explainability_output_path = \"s3://{}/{}/clarify-explainability\".format(bucket, prefix)\n",
    "explainability_data_config = clarify.DataConfig(\n",
    "    s3_data_input_path=clarify_path,\n",
    "    s3_output_path=explainability_output_path,\n",
    "    headers=clarify_data.columns.to_list(),\n",
    "    dataset_type=\"text/csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run-explainability-report\n",
    "\n",
    "clarify_processor.run_explainability(\n",
    "    data_config=explainability_data_config,\n",
    "    model_config=model_config,\n",
    "    explainability_config=shap_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.5: Remove the imbalance detected with SageMaker Clarify (optional)\n",
    "\n",
    "<a id=\"task4-5-continue\"></a>\n",
    "\n",
    "There are many ways to remove the imbalance detected with SageMaker Clarify. Use any method that you are familiar with. In this lab, a Synthetic Minority Over-sampling Technique (SMOTE) example is provided that removes bias from one of the columns.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> After you are finished removing the imbalance and want to retest, create a new resampled dataframe. You create and upload a new CSV file in the next task.\n",
    "\n",
    "For detailed steps how to remove imbalance, refer to <a href=\"#task4-5\" target=\"_self\">**Remove imbalance (Task 4.5)**</a> in the *Appendix* section.\n",
    "\n",
    "After you have removed any imbalance detected with SageMaker Clarify, you have completed this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_4_5_code_here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.6: Retrain the model (optional)\n",
    "\n",
    "<a id=\"task4-6-continue\"></a>\n",
    "\n",
    "Upload the new file to Amazon S3. Then, create a new estimator and retrain with the new data.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Use **s3_client.upload_file** to upload the new file to your bucket.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Use **xgboost_starter_script.py** and call **XGBoost**. Then, retrain with the new data.\n",
    "\n",
    "Did the retrained model achieve a higher F1 score? If you used SageMaker Debugger, were you able to resolve all of the discovered issues?\n",
    "\n",
    "For detailed steps how to retrain the model, refer to <a href=\"#task4-6\" target=\"_self\">**Retrain the model (Task 4.6)**</a> in the *Appendix* section.\n",
    "\n",
    "After you have retrained the model, you have completed this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_4_6_code_here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 5: Batch transform\n",
    "\n",
    "Your model is ready for deployment. Use a batch transform job with batch records and view the prediction and accuracy data in Amazon S3. Then, clean up some of your SageMaker instances.\n",
    "\n",
    "To complete this task, you complete the following subtasks:\n",
    "\n",
    "- Create a batch transform job for your model.\n",
    "- View the prediction data in Amazon S3.\n",
    "- Clean up SageMaker instances (optional).\n",
    "\n",
    "This challenge takes approximately *40* minutes to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.1: Create a batch transform job for your model\n",
    "\n",
    "<a id=\"task5-1-continue\"></a>\n",
    "\n",
    "Create a batch transform job using **transformer** on the model estimator. Then, run the batch job.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Use transformer and configure the **instance_count**, **instance_type**, **strategy**, **assemble_with**, and **output_path**.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Send your test data, which is listed in **test_path** to the endpoint and wait for the results.\n",
    "\n",
    "For detailed steps how to create a batch transform job, refer to <a href=\"#task5-1\" target=\"_self\">**Create a batch transform job (Task 5.1)**</a> in the *Appendix* section.\n",
    "\n",
    "After you have created a batch transform job and run it with a set of records, you have completed this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_5_1_code_here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.2: View the prediction data in Amazon S3\n",
    "\n",
    "<a id=\"task5-2-continue\"></a>\n",
    "\n",
    "When your batch transform job is complete, read the data from Amazon S3. \n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> You can copy data from the transformer output using **%aws s3 cp --recursive $transformer.output_path ./**\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> When you have the data, you can view it with **%head test_data_batch.csv.out**\n",
    "\n",
    "Take a look at the predictions. Are there any predictions that are surprising?\n",
    "\n",
    "For detailed steps how to view prediction data from a batch transform job, refer to <a href=\"#task5-2\" target=\"_self\">**View prediction data from a batch transform job (Task 5.2)**</a> in the *Appendix* section.\n",
    "\n",
    "After you have viewed the prediction data from the batch transform job, you have completed this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_5_2_code_here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.3: Clean up SageMaker instances (optional)\n",
    "\n",
    "To keep costs low, best practice is to delete instances that you are not using anymore. You can quickly delete instances using SageMaker Studio. Take a moment now to open your current resources list in SageMaker Studio and close out any remaining instances.\n",
    "\n",
    "If you plan to complete the next pipeline task, **leave the notebook instance running**.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> You can view a list of running instances by choosing the **Running Terminals and Kernels** icon in SageMaker Studio.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> You can use the **Shut down** icon to stop an instance.\n",
    "\n",
    "<a id=\"task5-3-continue\"></a>\n",
    "\n",
    "For detailed steps how to clean up SageMaker instances in SageMaker Studio, refer to <a href=\"#task5-3\" target=\"_self\">**Clean up SageMaker instances in SageMaker Studio (Task 5.3)**</a> in the *Appendix* section.\n",
    "\n",
    "After you have stopped all SageMaker instances in SageMaker Studio, you have completed this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 6: Build an automated pipeline (optional)\n",
    "\n",
    "Now that you have used the Amazon SageMaker Python SDK and the Amazon SageMaker Studio for a machine learning (ML) workflow, use SageMaker Pipelines to scale your workflow. Proceed through the provided pipeline script in the lab environment to complete this challenge. \n",
    "\n",
    "- Create the pipeline steps.\n",
    "    - Query processed data from SageMaker Feature Store.\n",
    "    - Train and tune the model.\n",
    "    - Evaluate the trained model.\n",
    "    - Conduct a batch transform job.\n",
    "    - Register a model.\n",
    "    - Evaluate model training with SageMaker Clarify.\n",
    "- Define and start the pipeline.\n",
    "- View ML Lineage Tracking.\n",
    "\n",
    "This challenge takes approximately *120* minutes to complete.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.1: Configure a pipeline\n",
    "\n",
    "<a id=\"task6-1-continue\"></a>\n",
    "\n",
    "Use a pipeline template and configure your inputs and outputs. When your configurations are ready, run the pipeline. Your pipeline can include a wide range of steps. Here is a suggested list of steps to configure:\n",
    "- **AutoModelProcess**: A **Processing** step that pulls in the .csv file and splits it into train, test, and validation datasets.\n",
    "- **AutoHyperParameterTuning**: A **Tuning** step that takes a range of hyperparameters and tunes the model.\n",
    "- **AutoEvalBestModel**: A **Processing** step that creates an evaluation report to describe the best model.\n",
    "- **CheckAUCScoreAutoEvaluation**: A **Condition** step that evaluates the models based on an evaluation metric. \n",
    "- **AutoCreateModel**: A **Model** step that creates a model.\n",
    "- **RegisterAutoModel-RegisterModel**: A **RegisterModel** step that registers a model.\n",
    "- **AutoModelConfigFile**: A **Processing** step that creates a bias report.\n",
    "- **AutoTransform**: A **Transform** step that runs a batch transform job.\n",
    "- **ClarifyProcessingStep**: A **Processing** step that runs a SageMaker Clarify job.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> There are many pipeline steps to pick from. To learn more about pipeline steps and view sample code for each step, refer to the *Build and manage pipeline steps* document in the *Additional resources* section for more information.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Start with a **Processing** step to pull your data in. Then, create a **Tuning** step to tune your model. Next, create a **Model** step to create your model.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> The detailed steps contain a sample solution, and includes steps to create evaluation reports, a bias report, run a batch transform job, and run a SageMaker Clarify job. \n",
    "\n",
    "For detailed steps how to configure a pipeline, refer to <a href=\"#task6-1\" target=\"_self\">**Configure a pipeline (Task 6.1)**</a> in the *Appendix* section.\n",
    "\n",
    "After you have set up the pipeline and started the pipeline job, you have completed this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_6_1_code_here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.2: Monitor the pipeline\n",
    "\n",
    "<a id=\"task6-2-continue\"></a>\n",
    "\n",
    "Monitor the pipeline while its running, viewing the inputs and outputs. \n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> Use `RunPipeline.describe()` to describe the pipeline that you just created.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> You can view the pipeline steps running in the SageMaker Studio UI. Open the **SageMaker resources** menu, choose **Pipelines**, and choose the pipeline that you created. \n",
    "\n",
    "For detailed steps how to monitor a pipeline, refer to <a href=\"#task6-2\" target=\"_self\">**Monitor a pipeline**</a> in the *Appendix* section.\n",
    "\n",
    "After you have finished monitoring the pipeline, you have completed this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_6_2_code_here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You used an auto insurance dataset to detect claims that are possibly fraudulent. You explored a technical solution to predict the likelihood that a given auto insurance claim is fraudulent using SageMaker Studio and the Amazon SageMaker Python SDK.\n",
    "\n",
    "### Cleanup\n",
    "\n",
    "You have completed this notebook. To move to the next part of the lab, do the following:\n",
    "\n",
    "- Close this notebook file.\n",
    "- Return to the lab session and continue with the **Conclusion**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional resources\n",
    "\n",
    "- [Autopilot metrics](https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-metrics-validation.html)\n",
    "- [Processing step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-1\" id=\"task1-1\"></a>\n",
    "\n",
    "### Appendix: Review your data (Task 1.1)\n",
    "\n",
    "To review your data, specify the path and load the data using Pandas. Take a moment to review a sample of both tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read-csv-files\n",
    "claims_data = pd.read_csv(\"./data/claims_preprocessed.csv\", index_col=0)\n",
    "customers_data = pd.read_csv(\"./data/customers_preprocessed.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#claims-data-sample\n",
    "claims_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customers-data-sample\n",
    "customers_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue this lab, return to <a href=\"#task1-1-continue\" target=\"_self\">Task 1.1</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-2-1\" id=\"task1-2-1\"></a>\n",
    "\n",
    "### Appendix: Explore a dataset in SageMaker Studio (Task 1.2)\n",
    "\n",
    "Start your data exploration in SageMaker Data Wrangler. Import your files from your S3 bucket and analyze the data.\n",
    "\n",
    "The next step opens SageMaker Data Wrangler. To follow these directions, use one of the following options:\n",
    "- **Option 1:** Open a new browser window for SageMaker Data Wrangler. Arrange the new window and the window displaying JupyterLab side-by-side. You can now have the directions visible as you explore the feature group.\n",
    "- **Option 2:** Open a new browser tab in the existing browser window for SageMaker Data Wrangler. Switch between the browser tabs to follow these instructions.\n",
    "\n",
    "1. From the browser tab with the initial lab instructions, copy the **SagemakerCanvasUrl** value to the left of the instructions.\n",
    "\n",
    "1. Open a new browser window (or tab), and then paste the **SagemakerCanvasUrl** into the address bar.\n",
    "\n",
    "1. Press **Enter**.\n",
    "\n",
    "1. On the **Amazon SageMaker Canvas** page, in the left menu, choose **Data Wrangler**.\n",
    "\n",
    "    SageMaker Canvas opens the **Data Wrangler** page.\n",
    "\n",
    "1. Choose **Import and prepare**.\n",
    "\n",
    "1. From the drop-down menu, choose **Tabular**.\n",
    "\n",
    "1. On the **Import tabular data** page, for the **Select a data source**, select **Amazon S3**.\n",
    "\n",
    "1. In the list of buckets, choose the Amazon S3 bucket name that starts with **databucket**.\n",
    "\n",
    "1. Select the checkbox next to **claims.csv** file.\n",
    "\n",
    "1. Choose **Next**.A preview of the first 100 rows of the dataset is displayed.\n",
    "\n",
    "1. Choose **Import**.\n",
    "\n",
    "    You have imported claims data from an Amazon S3 source into SageMaker Data Wrangler.\n",
    "\n",
    "1. In the **Learn more about your data** popup window, choose **Close**.\n",
    "\n",
    "    Next, you import customer data.\n",
    "\n",
    "1. Choose **Add data**.\n",
    "\n",
    "1. From the drop-down menu, choose **Tabular**.\n",
    "\n",
    "1. On the **Import tabular data** page, for the **Select a data source**, select **Amazon S3**.\n",
    "\n",
    "1. In the list of buckets, choose the Amazon S3 bucket name that starts with **databucket**.\n",
    "\n",
    "1. Select the checkbox next to **customers.csv** file.\n",
    "\n",
    "1. Choose **Next**.\n",
    "\n",
    "    A preview of the first 100 rows of the dataset is displayed.\n",
    "\n",
    "1. Choose **Import**.\n",
    "\n",
    "    You have imported customers data from an Amazon S3 source into SageMaker Data Wrangler.\n",
    "\n",
    "\n",
    "1. In the **Data Wrangler: Data flow** page, choose the **Data types** icon that is associated with the claims data. Choose the **+** sign next to it, and then choose **Get data insights**.\n",
    "\n",
    "1. Create a report and explore the insights.\n",
    "\n",
    "1. Choose **Data flow** to return to the diagram view.\n",
    "\n",
    "1. Choose the **+** sign next to the **Data types** icon associated with the customers data, and then choose **Get data insights**.\n",
    "\n",
    "1. Create a report and explore the results.\n",
    "\n",
    "    Use any report types that help you explore the datasets thoroughly. After you finish, you can continue with the next task.\n",
    "\n",
    "1. Leave the Data Wrangler page open. You will return to it later in the lab.\n",
    "\n",
    "To continue this lab, return to <a href=\"#task1-2-continue\" target=\"_self\">Task 1.2</a>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-2-2\" id=\"task1-2-2\"></a>\n",
    "\n",
    "### Appendix: Explore a dataset in the notebook (Task 1.2)\n",
    "\n",
    "You'll use JupyterLab to explore the datasets using code. There are many ways in which you can explore datasets. Here are several examples of some data exploration steps that you can take. Use these as a reference to start exploring aspects of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gender-graph\n",
    "import matplotlib.pyplot as plt\n",
    "customers_data.customer_gender_female.value_counts(normalize=True).plot.bar()\n",
    "plt.xticks([0, 1], [\"Male\", \"Female\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fraud-graph\n",
    "claims_data.fraud.value_counts(normalize=True).plot.bar()\n",
    "plt.xticks([0, 1], [\"Not Fraud\", \"Fraud\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#education-category-graphs\n",
    "educ = customers_data.customer_education.value_counts(normalize=True, sort=False)\n",
    "plt.bar(educ.index, educ.values)\n",
    "plt.xlabel(\"Customer Education Level\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#claim-amount-graph\n",
    "plt.hist(claims_data.total_claim_amount, bins=30)\n",
    "plt.xlabel(\"Total Claim Amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#claims-filed-graph\n",
    "customers_data.num_claims_past_year.hist(density=True)\n",
    "plt.suptitle(\"Number of Claims in the Past Year\")\n",
    "plt.xlabel(\"Number of claims per year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paid-plot-graphs\n",
    "sns.pairplot(\n",
    "    data=customers_data, vars=[\"num_insurers_past_5_years\", \"months_as_customer\", \"customer_age\"]\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fraud-insurers-graph\n",
    "combined_data = customers_data.join(claims_data)\n",
    "sns.lineplot(x=\"num_insurers_past_5_years\", y=\"fraud\", data=combined_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#months-as-customer-graph\n",
    "sns.boxplot(x=customers_data[\"months_as_customer\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customer-age-graph\n",
    "sns.boxplot(x=customers_data[\"customer_age\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fraud-gender-graph\n",
    "combined_data.groupby(\"customer_gender_female\").mean()[\"fraud\"].plot.bar()\n",
    "plt.xticks([0, 1], [\"Male\", \"Female\"])\n",
    "plt.suptitle(\"Fraud by Gender\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation-matrix-graph\n",
    "cols = [\n",
    "    \"fraud\",\n",
    "    \"customer_gender_male\",\n",
    "    \"customer_gender_female\",\n",
    "    \"months_as_customer\",\n",
    "    \"num_insurers_past_5_years\",\n",
    "]\n",
    "corr = combined_data[cols].corr()\n",
    "\n",
    "# plot the correlation matrix\n",
    "sns.heatmap(corr, annot=True, cmap=\"Reds\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load-combined-data\n",
    "combined_data = pd.read_csv(\"./data/claims_customer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove-unnecessary-columns\n",
    "combined_data = combined_data.loc[:, ~combined_data.columns.str.contains(\"^Unnamed: 0\")]\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe-combined-data\n",
    "combined_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate-statistics\n",
    "combined_stats = []\n",
    "\n",
    "for col in combined_data.columns:\n",
    "    combined_stats.append(\n",
    "        (\n",
    "            col,\n",
    "            combined_data[col].nunique(),\n",
    "            combined_data[col].isnull().sum() * 100 / combined_data.shape[0],\n",
    "            combined_data[col].value_counts(normalize=True, dropna=False).values[0] * 100,\n",
    "            combined_data[col].dtype,\n",
    "        )\n",
    "    )\n",
    "\n",
    "stats_df = pd.DataFrame(\n",
    "    combined_stats,\n",
    "    columns=[\"feature\", \"unique_values\", \"percent_missing\", \"percent_largest_category\", \"datatype\"],\n",
    ")\n",
    "stats_df.sort_values(\"percent_largest_category\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap-graph\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "corr_list = [\n",
    "    \"customer_age\",\n",
    "    \"months_as_customer\",\n",
    "    \"total_claim_amount\",\n",
    "    \"injury_claim\",\n",
    "    \"vehicle_claim\",\n",
    "    \"incident_severity\",\n",
    "    \"fraud\",\n",
    "]\n",
    "\n",
    "corr_df = combined_data[corr_list]\n",
    "corr = round(corr_df.corr(), 2)\n",
    "\n",
    "fix, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "mask = np.zeros_like(corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "ax = sns.heatmap(corr, mask=mask, ax=ax, annot=True, cmap=\"OrRd\")\n",
    "\n",
    "ax.set_xticklabels(ax.xaxis.get_ticklabels(), fontsize=10, ha=\"right\", rotation=45)\n",
    "ax.set_yticklabels(ax.yaxis.get_ticklabels(), fontsize=10, va=\"center\", rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue this lab, return to <a href=\"#task1-2-continue\" target=\"_self\">Task 1.2</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-3-1\" id=\"task1-3-1\"></a>\n",
    "\n",
    "### Appendix: Joining tables in SageMaker Studio (Task 1.3)\n",
    "\n",
    "1. In the **SageMaker Canvas** tab, choose **New data flow *DateTime*.flow**.\n",
    "\n",
    "    <i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> *DateTime* is the time the flow was first created. The format will be similar to *2024-10-23 11:15:07 AM*.\n",
    "\n",
    "1. Choose the **+** sign next to the **claims.csv Data types** icon.\n",
    "\n",
    "1. From the context menu, choose **Combine data**, and then select **Join**.\n",
    "\n",
    "    SageMaker Data Wrangler displays the **Join** pane on the right sid of the page.\n",
    "\n",
    "   <i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> To better view the flow diagram, you can zoom in and out. You can also drag the canvas to bring the icons with which you want to work into view.\n",
    "\n",
    "1. In the Data flow diagram, choose the **Data types** icon associated with **customers.csv**.\n",
    "\n",
    "    The customers.csv data is added to the **Join** pane.\n",
    "\n",
    "1. For **Join Type**, select **Inner join**.\n",
    "1. In the **Join keys** section:\n",
    "\n",
    "    - For **Left**, select `policy_id`.\n",
    "    \n",
    "    - For **Right**, select `policy_id`.\n",
    "\n",
    "1. Choose **Preview**.\n",
    "\n",
    "1. Choose **Add**.\n",
    "\n",
    "1. When you navigate away from this page, leave it open. You will use it again later in the lab.\n",
    "\n",
    "To continue this lab, return to <a href=\"#task1-3-continue\" target=\"_self\">Task 1.3</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-3-2\" id=\"task1-3-2\"></a>\n",
    "\n",
    "### Appendix: Run a pre-training bias report (Task 1.3)\n",
    "\n",
    "Create a SageMaker Clarify bias report using a SageMaker Data Wrangler flow.\n",
    "\n",
    "1. In the **SageMaker Canvas** tab, choose **New data flow *DateTime*.flow**.\n",
    "\n",
    "    <i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> *DateTime* is the time the flow was first created. The format will be similar to *2024-10-23 11:15:07 AM*.\n",
    "    \n",
    "1. Choose the **Join** icon, and then choose the **+** sign next to it.\n",
    "1. From the context menu, choose **Get data insights**.\n",
    "1. In the **Create analysis** section:\n",
    "\n",
    "    - For **Analysis type**, select **Bias Report**.\n",
    "    - For **Analysis name**, enter `fraud bias by age`.\n",
    "    - For **Select the column your model predicts (target)**, select **fraud**.\n",
    "    - For **Is your predicted column a value or threshold?**, choose the **value** option.\n",
    "    - For **Predicted value(s)**, enter **1**.\n",
    "    - For **Select the column to analyze for bias**, select **customer_age**.\n",
    "\n",
    "1. Choose **Create**.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> If you receive the error **An unexpected internal error has occurred. Try your request again. If the problem persists, contact AWS support**, wait one minute. Then choose the **Bias Report** tab title.\n",
    "\n",
    "After the job is finished, view the returned metrics. Take note if there is bias and plan any processing steps that you want to take on the column that you analyzed. \n",
    "\n",
    "You can repeat these steps for any columns that you want to analyze for bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue this lab, return to <a href=\"#task1-3-continue\" target=\"_self\">Task 1.3</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-4-1\" id=\"task1-4-1\"></a>\n",
    "\n",
    "### Appendix: Prepare data using SageMaker Data Wrangler (Task 1.4)\n",
    "\n",
    "Combine the datasets, join them in SageMaker Data Wrangler using the **policy_id**.\n",
    "\n",
    "With SageMaker Data Wrangler, you can join data at any point in the flow. You can complete data preparation on the individual files before joining them, or you can transform the features after the join. A SageMaker Data Wrangler flow is flexible.\n",
    "\n",
    "If you have not joined the tables in task 1.3, the following steps guide you through the process.\n",
    "\n",
    "1. To return to the **Data flow** view, in the SageMaker Canvas tab, choose **New data flow *DateTime*.flow**.\n",
    "\n",
    "    <i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> *DateTime* is the time the flow was first created. The format will be similar to *2024-10-23 11:15:07 AM*.\n",
    "\n",
    "1. Choose the **+** sign next to the **claims.CSV Data types** icon.\n",
    "\n",
    "1. From the context menu, choose **Combine data**, and then select **Join**.\n",
    "\n",
    "    SageMaker Data Wrangler displays the **Join** pane on the right sid of the page.\n",
    "\n",
    "    <i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> To better view the Data flow diagram, you can zoom in and out. You can also drag the diagram image to bring the icons with which you want to work into view.\n",
    "\n",
    "1. In the Data flow diagram, choose the  **customers.csv Data types** icon.\n",
    "\n",
    "    The customers.csv data is added to the **Join** pane.\n",
    "\n",
    "1. For **Join Type**, select **Inner join**.\n",
    "1. In the **Join keys** section:\n",
    "\n",
    "    - For **Left**, select `policy_id`.\n",
    "    \n",
    "    - For **Right**, select `policy_id`.\n",
    "\n",
    "1. Choose **Preview**.\n",
    "\n",
    "1. Choose **Add**.\n",
    "\n",
    "SageMaker Data Wrangler displays the **Join** page.\n",
    "\n",
    "With the data tables joined, transform the combined data.\n",
    "\n",
    "1. To return to the **Data flow** view, in the SageMaker Canvas tab, choose **New data flow *DateTime*.flow**.\n",
    "\n",
    "1. Choose the **Join** icon, and then choose the **+** sign next to it. \n",
    "\n",
    "1. From the context menu, choose **+** **Add transform**.\n",
    "\n",
    "Multiple transformations can be added to data sets using this menu. A preview of the dataset is shown in the center of the page.\n",
    "\n",
    "Add the following transform steps to the SageMaker Data Wrangler flow:\n",
    "- Encode categorical (One-hot encoding): **authorities_contacted**, **collision_type**, **customer_gender**, **driver_relationship**, **incident_type**, and **policy_state**. In the **Advanced** section, use a **Skip** invalid handling strategy, select output style of **Columns**.\n",
    "- Encode categorical (Ordinal encode): **customer_education**, **incident_severity**, **police_report_available**, and **policy_liability** using a **Skip** invalid handling strategy.\n",
    "- Parse column as type: **vehicle_claim** and **total_claim_amount** from **Float** to **Long**.\n",
    "- Manage columns (Drop column): **customer_zip** and **policy_id_1**.\n",
    "- Manage columns (Move column): **fraud** (using **Move to start**).\n",
    "- Manage columns (Rename column): Replace the **/** symbol from **collision_type_N/A**, and **driver_relationship_N/A** with a **_**.\n",
    "- Manage columns (Rename column): Rename **policy_id_0** to **policy_id**.\n",
    "\n",
    "If any column name has a **/** character in it, rename the column to replace **/** with **_**. If any column name has a blank space character in it, rename the column to replace the blank space with **_**. For example, any column created with one-hot encoding that has **N/A** as a value need to be renamed. SageMaker Feature Store does not accept columns with a **/** or blank space characters in it.\n",
    "\n",
    "When you have transformed your data and are ready to start training your model, you can continue to the next task. You can always return to this flow and make changes based on your findings during training and tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue this lab, return to <a href=\"#task1-4-continue\" target=\"_self\">Task 1.4</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-4-2\" id=\"task1-4-2\"></a>\n",
    "\n",
    "### Appendix: Import an example set of processed data (Task 1.4)\n",
    "\n",
    "If you get stuck during preprocessing or want to load a set of data that has been processed for you, access the processed data stored in the data folder in your S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed-data-import\n",
    "s3_client.upload_file(Filename=\"data/claims_customer.csv\", Bucket=bucket, Key=f\"{prefix}/data/raw/claims_customer.csv\")\n",
    "df_processed = pd.read_csv(\"./data/claims_customer.csv\", index_col=None)\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue this lab, return to <a href=\"#task1-4-continue\" target=\"_self\">Task 1.4</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task2-1\" id=\"task2-1\"></a>\n",
    "\n",
    "### Appendix: Create a feature group using the Export to option (Task 2.1)\n",
    "\n",
    "SageMaker Data Wrangler can export data to SageMaker Feature Store. It creates a notebook with all the code required to configure a feature group and ingest your transformed data into the feature group.\n",
    "\n",
    "1. Choose **Add transform**.\n",
    "\n",
    "1. Choose **Custom transform**.\n",
    "\n",
    "1. For **Name**, enter `event_time`. \n",
    "\n",
    "1. Select **Python (PySpark)** if it is not already selected.\n",
    "\n",
    "1. For **Your custom transform**, enter the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "from pyspark.sql.functions import lit\n",
    "date_time = datetime.date.today()\n",
    "\n",
    "df = df.withColumn(\"event_time\", lit(time.mktime(date_time.timetuple())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Choose **Preview**.\n",
    "\n",
    "1. Choose **Add**.\n",
    "\n",
    "This adds **event_time** as a column to your dataset. SageMaker Feature Store requires an **event_time** and a unique **record** ID. Use **policy_id** as your **record** ID.\n",
    "\n",
    "Next you will rename the data flow.\n",
    "\n",
    "1. From the left menu, choose the **Data Wrangler** icon.\n",
    "\n",
    "1. Hover your mouse over the entry for **New data flow *DateTime*.flow** and choose the menu icon that appears.\n",
    "\n",
    "1. From the context menu, select **Rename**.\n",
    "\n",
    "1. For **Flow name** enter `CapstoneDataWrangler`.\n",
    "\n",
    "1. To return to the **Data flow** view, choose **CapstoneDataWrangler.flow**.\n",
    "\n",
    "1. Choose the **+** icon next to your final transformation in SageMaker Data Wrangler.\n",
    "\n",
    "1. Choose **Export**.\n",
    "\n",
    "1. From the context menu, select **Export via Jupyter notebook**, then select **SageMaker Feature Store**.\n",
    "\n",
    "1. Select Download as **local copy**, and then choose **Download**. \n",
    "\n",
    "1. Choose **Save**.\n",
    "\n",
    "Now, you will upload the notebook to JupyterLab, edit the **CapstoneDataWrangler** notebook code, and run the notebook.\n",
    "\n",
    "1. Return to the **JupyterLab** tab.\n",
    "\n",
    "1. Above the file list, choose the upload icon and upload the **CapstoneDataWrangler.zip** file that you just downloaded from SageMaker Data Wrangler.\n",
    "\n",
    "1. In the JupyterLab browser tab, next to the **capstone.ipynb** tab, select the **+** symbol.\n",
    "\n",
    "1. Choose the **Terminal** icon and enter the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cd capstone\n",
    "unzip CapstoneDataWrangler.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. From the file list, locate and open the **CapstoneDataWrangler.ipynb** file.\n",
    "\n",
    "1. In the **Select Kernel** pop-up window, verify that `Python (ipylernel)` is selected, and then choose **Select**.\n",
    "\n",
    "1. In the first cell, change the following variables:\n",
    "- For **record_identifier_feature_name**, replace **None** with `\"policy_id\"`. If you joined the customers and claims tables together and did not drop the second **policy_id** column, you might need to replace **None** with `\"policy_id_0\"`. Do not change the **None** value after the **if** statement.\n",
    "- For **event_time_feature_name**, replace **None** with `\"event_time\"`. Do not change the **None** value after the **if** statement.\n",
    "\n",
    "**Expected output:** When you are done editing the cell, it should resemble this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_identifier_feature_name = \"policy_id\"\n",
    "if record_identifier_feature_name is None:\n",
    "   raise SystemExit(\"Select a column name as the feature group record identifier.\")\n",
    "\n",
    "event_time_feature_name = \"event_time\"\n",
    "if event_time_feature_name is None:\n",
    "   raise SystemExit(\"Select a column name as the event time feature name.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <i aria-hidden=\"true\" class=\"fas fa-exclamation-circle\" style=\"color:#7C5AED\"></i> **Caution:** Search the **CapstoneDataWrangler** notebook for the `container_uri` variable  and replace the value as follows:\n",
    "\n",
    "    <i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> If you are running the lab in the **us-east-1** region, replace the current value with: `663277389841.dkr.ecr.us-east-1.amazonaws.com/sagemaker-data-wrangler-container:2.x`\n",
    "\n",
    "    <i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> If you are running the lab in the **us-west-2** region, replace the current value with: `174368400705.dkr.ecr.us-west-2.amazonaws.com/sagemaker-data-wrangler-container:2.x`\n",
    "\n",
    "The update code should be similar to the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canvas Container URL.\n",
    "container_uri = \"174368400705.dkr.ecr.us-west-2.amazonaws.com/sagemaker-data-wrangler-container:2.x\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Beginning from the first cell, run through all the cells in the CapstoneDataWrangler notebook to create a feature definition, a feature group, and ingest the transformed data into the feature group using a processing job. \n",
    "\n",
    "When the cells are complete, your feature store is ready to use.\n",
    "\n",
    "To continue this lab, return to <a href=\"#task2-1-continue\" target=\"_self\">Task 2.1</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task2-2\" id=\"task2-2\"></a>\n",
    "\n",
    "### Appendix: Extract records from an offline store with Athena (Task 2.2)\n",
    "\n",
    "In the **capstone.ipynb** notebook, set up an Athena query with **athena_query**. Then, set your **query_string**. Finally, run the query and view a sample of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-and-run-athena-query\n",
    "try:\n",
    "    # If there is a feature group, get the name\n",
    "    feature_group_name = sagemaker_session.boto_session.client(\"sagemaker\", region_name=region).list_feature_groups()['FeatureGroupSummaries'][0]['FeatureGroupName']\n",
    "    feature_group = FeatureGroup(name=feature_group_name, sagemaker_session=sagemaker_session)\n",
    "\n",
    "    # Confirm the Athena settings are configured\n",
    "    try:\n",
    "        boto3.client('athena').update_work_group(\n",
    "            WorkGroup='primary',\n",
    "            ConfigurationUpdates={\n",
    "                'EnforceWorkGroupConfiguration':False\n",
    "            }\n",
    "        )\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Configure the query\n",
    "    query = feature_group.athena_query()\n",
    "    table = query.table_name\n",
    "    query_string = f'SELECT * FROM \"{table}\" '\n",
    "    output_location = f\"s3://{sagemaker_session.default_bucket()}/query_results/\"\n",
    "    print(f\"Athena query output location: \\n{output_location}\")\n",
    "\n",
    "    # Run the query\n",
    "    query.run(query_string=query_string, output_location=output_location)\n",
    "    query.wait()\n",
    "    df_feature_store = query.as_dataframe()\n",
    "    \n",
    "    # Wait for data to appear in the feature group\n",
    "    attempts = 0\n",
    "    while len(df_feature_store.index) == 0 and attempts < 30:\n",
    "        print(\"Waiting for feature group to populate...\")\n",
    "        time.sleep(60)\n",
    "        # Rerun the query\n",
    "        query.run(query_string=query_string, output_location=output_location)\n",
    "        query.wait()\n",
    "        df_feature_store = query.as_dataframe()\n",
    "        # Increment the attempts\n",
    "        attempts += 1\n",
    "    if len(df_feature_store.index) != 0:\n",
    "        print(\"The feature group is populated.\")\n",
    "except IndexError as e:\n",
    "    # If there is no feature group, thrown an error\n",
    "    print(\"No feature groups were found. Please create a feature group.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the previous code block, the Amazon Athena query records are saved in the Amazon S3 bucket which has a name starting with *sagemaker*. The saved query object is in a directory named **query_results**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue this lab, return to <a href=\"#task2-2-continue\" target=\"_self\">Task 2.2</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task3-1\" id=\"task3-1\"></a>\n",
    "\n",
    "### Appendix: Name an experiment and a run (Task 3.1)\n",
    "\n",
    "To create an experiment, use the library **sagemaker.experiments.run**. Set the **experiment_name**, a **run_name**, and the **description**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "#create experiment and run-names\n",
    "create_date = strftime(\"%m%d%H%M\")\n",
    "capstone_experiment_name=\"capstone-experiment-{}\".format(create_date)\n",
    "capstone_run_name = \"lab-capstone-run-{}\".format(create_date)\n",
    "\n",
    "# define a run_tag\n",
    "run_tags = [{'Key': 'lab-capstone', 'Value': 'lab-capstone-run'}]\n",
    "\n",
    "# provide a description\n",
    "description=\"Using SM Experiments with the Auto dataset.\"\n",
    "\n",
    "print(f\"Experiment name - {capstone_experiment_name},  run name - {capstone_run_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue this lab, return to <a href=\"#task3-1-continue\" target=\"_self\">Task 3.1</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task3-2\" id=\"task3-2\"></a>\n",
    "\n",
    "### Appendix: Split data into train, test, and validation datasets (Task 3.2)\n",
    "\n",
    "To split your data, use **np.split** and specify how you want to split your data. Then, create CSV files and upload them to your S3 bucket. Next, set up your training inputs. Finally, create your **data_inputs** variable. Use the data_inputs throughout the challenge to specify the train and validation datasets when training your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-validation-test-split\n",
    "try:\n",
    "    # If there is a feature group, use it\n",
    "    df_feature_store = df_feature_store.iloc[: , :-4]\n",
    "    df_processed_pre_split = df_feature_store\n",
    "    print(\"Using the records from the feature group\")\n",
    "except NameError:\n",
    "    # If there is no feature group, use the processed dataset\n",
    "    df_processed = pd.read_csv(\"./data/claims_customer.csv\", index_col=None)\n",
    "    df_processed_pre_split = df_processed\n",
    "    print(\"Using the processed records from Amazon S3\")\n",
    "\n",
    "# Split the data into train, validation, and test datasets\n",
    "train_data, validation_data, test_data = np.split(\n",
    "    df_processed_pre_split.sample(frac=1, random_state=1729),\n",
    "    [int(0.7 * len(df_processed_pre_split)), int(0.9 * len(df_processed_pre_split))],\n",
    ")\n",
    "\n",
    "# Create the CSV files and upload them to your default bucket\n",
    "train_data.to_csv(\"train_data.csv\", index=False, header=False)\n",
    "validation_data.to_csv(\"validation_data.csv\", index=False, header=False)\n",
    "test_data.to_csv(\"test_data.csv\", index=False, header=False)\n",
    "\n",
    "train_path = S3Uploader.upload(\"train_data.csv\", \"s3://{}/{}\".format(bucket, prefix))\n",
    "validation_path = S3Uploader.upload(\"validation_data.csv\", \"s3://{}/{}\".format(bucket, prefix))\n",
    "test_path = S3Uploader.upload(\"test_data.csv\", \"s3://{}/{}\".format(bucket, prefix))\n",
    "\n",
    "# Set the training inputs\n",
    "train_input = TrainingInput(train_path, content_type=\"text/csv\")\n",
    "validation_input = TrainingInput(validation_path, content_type=\"text/csv\")\n",
    "test_input = TrainingInput(test_path, content_type=\"text/csv\")\n",
    "\n",
    "data_inputs = {\n",
    "    \"train\": train_input,\n",
    "    \"validation\": validation_input\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue this lab, return to <a href=\"#task3-2-continue\" target=\"_self\">Task 3.2</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task3-3-1\" id=\"task3-3-1\"></a>\n",
    "\n",
    "### Appendix: Configure and run a basic training job (Task 3.3)\n",
    "\n",
    "If you want to start with a basic training job, use the basic **XGBoost** container. Then, configure your estimator, noting the container and role that you want to use. When those configurations are set, you can choose your hyperparameters. You can use the default values that are provided in the code that follows, or you can edit them based on your findings during data preparation.\n",
    "\n",
    "To run the training job, call **fit()**, setting the inputs as your **data_inputs** variable and setting your configurations for a **run_name**, and a **experiment_name**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker import image_uris\n",
    "#train-model\n",
    "# Retrieve the container image\n",
    "container = sagemaker.image_uris.retrieve(\n",
    "    region=boto3.Session().region_name, \n",
    "    framework=\"xgboost\", \n",
    "    version=\"1.5-1\"\n",
    ")\n",
    "\n",
    "# Set the hyperparameters\n",
    "eta=0.2\n",
    "gamma=4\n",
    "max_depth=4\n",
    "min_child_weight=6\n",
    "num_round=800\n",
    "objective='binary:logistic'\n",
    "subsample=0.8\n",
    "\n",
    "hyperparameters = {\n",
    "    \"eta\":eta,\n",
    "    \"gamma\":gamma,\n",
    "    \"max_depth\":max_depth,\n",
    "    \"min_child_weight\":min_child_weight,\n",
    "    \"num_round\":num_round,\n",
    "    \"objective\":objective,\n",
    "    \"subsample\":subsample\n",
    "}\n",
    "\n",
    "# Set up the estimator\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,    \n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.m5.4xlarge\",\n",
    "    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    max_run=1800,\n",
    "    hyperparameters=hyperparameters,\n",
    "    tags = run_tags\n",
    ")\n",
    "\n",
    "with Run(\n",
    "    experiment_name=capstone_experiment_name,\n",
    "    run_name=capstone_run_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "    run.log_parameter(\"eta\", eta)\n",
    "    run.log_parameter(\"gamma\", gamma)\n",
    "    run.log_parameter(\"max_depth\", max_depth)\n",
    "    run.log_parameter(\"min_child_weight\", min_child_weight)\n",
    "    run.log_parameter(\"objective\", objective)\n",
    "    run.log_parameter(\"subsample\", subsample)\n",
    "    run.log_parameter(\"num_round\", num_round)\n",
    "\n",
    "# Train the model associating the training run with the current \"experiment\"\n",
    "    xgb.fit(\n",
    "        inputs = data_inputs\n",
    "    )        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue this lab, return to <a href=\"#task3-3-continue\" target=\"_self\">Task 3.3</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task3-3-2\" id=\"task3-3-2\"></a>\n",
    "\n",
    "### Appendix: Configure and run a training job with SageMaker Debugger enabled and analyze reports (Task 3.3)\n",
    "\n",
    "SageMaker Debugger helps you find additional reports that can inform your hyperparameter tuning quickly, saving time when you start to run more training jobs with hyperparameter ranges. To enable the debugger, configure your **DebuggerHookConfig** and **rules**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enable-debugger\n",
    "# Retrieve the container image\n",
    "container = sagemaker.image_uris.retrieve(\n",
    "    region=boto3.Session().region_name, \n",
    "    framework=\"xgboost\", \n",
    "    version=\"1.5-1\"\n",
    ")\n",
    "\n",
    "# Set the hyperparameters\n",
    "eta=0.2\n",
    "gamma=4\n",
    "max_depth=4\n",
    "min_child_weight=6\n",
    "num_round=300\n",
    "objective='binary:logistic'\n",
    "subsample=0.7\n",
    "        \n",
    "hyperparameters = {\n",
    "        \"eta\":eta,\n",
    "        \"gamma\":gamma,\n",
    "        \"max_depth\":max_depth,\n",
    "        \"min_child_weight\":min_child_weight,\n",
    "        \"num_round\":num_round,\n",
    "        \"objective\":objective,\n",
    "        \"subsample\":subsample\n",
    "}\n",
    "\n",
    "# Set up the estimator\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role, \n",
    "    base_job_name=base_job_name,\n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.m5.4xlarge\",\n",
    "    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    max_run=1800,\n",
    "    hyperparameters=hyperparameters,\n",
    "    tags = run_tags,\n",
    "\n",
    "    #Set the Debugger Hook Config\n",
    "    debugger_hook_config=DebuggerHookConfig(\n",
    "        s3_output_path=bucket_path,  # Required\n",
    "        collection_configs=[\n",
    "            CollectionConfig(name=\"metrics\", parameters={\"save_interval\": str(save_interval)}),\n",
    "            CollectionConfig(name=\"feature_importance\", parameters={\"save_interval\": str(save_interval)},),\n",
    "            CollectionConfig(name=\"full_shap\", parameters={\"save_interval\": str(save_interval)}),\n",
    "            CollectionConfig(name=\"average_shap\", parameters={\"save_interval\": str(save_interval)}),\n",
    "        ],\n",
    "        ),\n",
    "        #Set the Debugger Profiler Configuration\n",
    "        profiler_config = ProfilerConfig(\n",
    "            system_monitor_interval_millis=500,\n",
    "            framework_profile_params=FrameworkProfile()\n",
    "    ),\n",
    "        #Configure the Debugger Rule Object\n",
    "        rules = [\n",
    "            ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "            Rule.sagemaker(rule_configs.create_xgboost_report()),  \n",
    "            Rule.sagemaker(rule_configs.overfit()),\n",
    "            Rule.sagemaker(rule_configs.overtraining()),\n",
    "            Rule.sagemaker(rule_configs.loss_not_decreasing(),\n",
    "                rule_parameters={\n",
    "                    \"collection_names\": \"metrics\",\n",
    "                    \"num_steps\": str(save_interval * 2),\n",
    "                }\n",
    "            )\n",
    "    ]\n",
    ")\n",
    "with Run(\n",
    "    experiment_name=capstone_experiment_name,\n",
    "    run_name=capstone_run_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "    run.log_parameter(\"eta\", eta)\n",
    "    run.log_parameter(\"gamma\", gamma)\n",
    "    run.log_parameter(\"max_depth\", max_depth)\n",
    "    run.log_parameter(\"min_child_weight\", min_child_weight)\n",
    "    run.log_parameter(\"objective\", objective)\n",
    "    run.log_parameter(\"subsample\", subsample)\n",
    "    run.log_parameter(\"num_round\", num_round)\n",
    "# Train the model\n",
    "xgb.fit(\n",
    "    inputs = data_inputs\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue this lab, return to <a href=\"#task3-3-continue\" target=\"_self\">Task 3.3</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task3-4\" id=\"task3-4\"></a>\n",
    "\n",
    "### Appendix: Configure training hyperparameter ranges (Task 3.4)\n",
    "\n",
    "Now that you have trained at least one model, you can use what you learned from data processing and SageMaker Debugger to inform what ranges you select for your hyperparameters. Edit the following hyperparameter ranges and run the tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune-model\n",
    "# Setup the hyperparameter ranges\n",
    "hyperparameter_ranges = {\n",
    "    \"alpha\": ContinuousParameter(0, 2),\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "    \"max_depth\": IntegerParameter(1, 4),\n",
    "    \"min_child_weight\": ContinuousParameter(1, 10),\n",
    "    \"num_round\": IntegerParameter(100, 1000)\n",
    "}\n",
    "\n",
    "# Define the target metric and the objective type (max/min)\n",
    "objective_metric_name = \"validation:auc\"\n",
    "objective_type=\"Maximize\"\n",
    "\n",
    "# Define the HyperparameterTuner\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator = xgb,\n",
    "    objective_metric_name = objective_metric_name,\n",
    "    hyperparameter_ranges = hyperparameter_ranges,\n",
    "    objective_type = objective_type,\n",
    "    max_jobs=12,\n",
    "    max_parallel_jobs=4,\n",
    "    early_stopping_type=\"Auto\"\n",
    ")\n",
    "\n",
    "# Tune the model\n",
    "tuner.fit(\n",
    "    inputs = data_inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue this lab, return to <a href=\"#task3-4-continue\" target=\"_self\">Task 3.4</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-1\" id=\"task4-1\"></a>\n",
    "\n",
    "### Appendix: Create a model (Task 4.1)\n",
    "\n",
    "Create a XGBoost model, calling **create_model** with the **model_name**, **role**, and **container_def** that you define."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model-configurations\n",
    "model_name = \"capstone-clarify-model\"\n",
    "model = xgb.create_model(name=model_name)\n",
    "container_def = model.prepare_container_def()\n",
    "sagemaker_session.create_model(model_name, role, container_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue this lab, return to <a href=\"#task4-1-continue\" target=\"_self\">Task 4.1</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-2\" id=\"task4-2\"></a>\n",
    "\n",
    "### Appendix: Create a SageMaker Clarify model configuration (Task 4.2)\n",
    "\n",
    "Create a SageMaker Clarify model configuration using **SageMakerClarifyProcessor**. Set the **instance_count** and the **instance_type**. Use the **role** and **session** created at the beginning of the Capstone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define-clarify-processor\n",
    "clarify_processor = clarify.SageMakerClarifyProcessor(\n",
    "    role=role, \n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.m5.xlarge\", \n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue this lab, return to <a href=\"#task4-2-continue\" target=\"_self\">Task 4.2</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-3\" id=\"task4-3\"></a>\n",
    "\n",
    "### Appendix: Create a SageMaker Clarify bias configuration (Task 4.3)\n",
    "\n",
    "To create a SageMaker Clarify bias configuration, choose an output path for the data, set the input path from the training job, in addition to the **label**, **headers**, and **dataset_type**.\n",
    "\n",
    "Then, you create a **ModelConfig** and **ModelPredictedLabelConfig**.\n",
    "\n",
    "Lastly, you configure a **BiasConfig** with the fields that you want SageMaker Clarify to observe. You can add or remove any fields that you are interested in exploring based on your initial findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define-data-config\n",
    "bias_report_output_path = \"s3://{}/{}/clarify-bias\".format(bucket, prefix)\n",
    "bias_data_config = clarify.DataConfig(\n",
    "    s3_data_input_path=train_path,\n",
    "    s3_output_path=bias_report_output_path,\n",
    "    label=\"fraud\",\n",
    "    headers=train_data.columns.to_list(),\n",
    "    dataset_type=\"text/csv\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define-model-config\n",
    "model_config = clarify.ModelConfig(\n",
    "    model_name=model_name,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    accept_type=\"text/csv\",\n",
    "    content_type=\"text/csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define-label-config\n",
    "predictions_config = clarify.ModelPredictedLabelConfig(probability_threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define-bias-config\n",
    "bias_config = clarify.BiasConfig(\n",
    "    label_values_or_threshold=[1], facet_name=\"customer_gender_female\", facet_values_or_threshold=[0], group_name=\"customer_age\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue this lab, return to <a href=\"#task4-3-continue\" target=\"_self\">Task 4.3</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-4\" id=\"task4-4\"></a>\n",
    "\n",
    "### Appendix: Run bias, data, and model reports using SageMaker Clarify (Task 4.4)\n",
    "\n",
    "Now that your SageMaker Clarify job is configured, run the job by calling **run_bias**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run-bias-report\n",
    "clarify_processor.run_bias(\n",
    "    data_config=bias_data_config,\n",
    "    bias_config=bias_config,\n",
    "    model_config=model_config,\n",
    "    model_predicted_label_config=predictions_config,\n",
    "    pre_training_methods=\"all\",\n",
    "    post_training_methods=\"all\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue this lab, return to <a href=\"#task4-4-continue\" target=\"_self\">Task 4.4</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-5\" id=\"task4-5\"></a>\n",
    "\n",
    "### Appendix: Remove imbalance (Task 4.5)\n",
    "\n",
    "In this example, you are upsampling **customer_gender_female** to reduce bias in the dataset. If you find other features that contain bias, you can also remove imbalance on those features. The **random_state** has been set to `42`, but you can change this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display-summary\n",
    "gender = train_data[\"customer_gender_female\"]\n",
    "gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove-imbalance\n",
    "sm = SMOTE(random_state=42)\n",
    "train_data_upsampled, gender_res = sm.fit_resample(train_data, gender)\n",
    "train_data_upsampled[\"customer_gender_female\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue this lab, return to <a href=\"#task4-5-continue\" target=\"_self\">Task 4.5</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-6\" id=\"task4-6\"></a>\n",
    "\n",
    "### Appendix: Retrain the model (Task 4.6)\n",
    "\n",
    "You have found imbalance and have a new training dataset. Use this dataset and retrain the file. To do this, upload the new file and create a new estimator. Then, retrain the data with **fit()**. Several hyperparameters are included in the following code as a sample. You can add, remove, or adjust these as needed during retraining to find the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload-upsampled-csv\n",
    "train_data_upsampled.to_csv(\"data/upsampled_train.csv\", index=False, header=False)\n",
    "retrain_path = S3Uploader.upload(\"data/upsampled_train.csv\", \"s3://{}/{}\".format(bucket, prefix))\n",
    "retrain_input = TrainingInput(retrain_path, content_type=\"text/csv\")\n",
    "\n",
    "retrain_data_inputs = {\n",
    "    \"train\": retrain_input,\n",
    "    \"validation\": validation_input\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create-estimator\n",
    "hyperparameters= {\n",
    "    \"max_depth\": \"4\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"subsample\": \"0.7\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_round\": \"300\",\n",
    "}\n",
    "\n",
    "xgb_retrained = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role, \n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters=hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrain-upsampled-data\n",
    "xgb_retrained.fit(\n",
    "    inputs = retrain_data_inputs\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue this lab, return to <a href=\"#task4-6-continue\" target=\"_self\">Task 4.6</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task5-1\" id=\"task5-1\"></a>\n",
    "\n",
    "### Appendix: Create a batch transform job (Task 5.1)\n",
    "\n",
    "Use your model estimator and create a batch transform job with **transformer**. Set the strategy to **MultiRecord** to increase the processing efficiency. Then, pass in your **test_path** and wait for the inference to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create-batch-transformer\n",
    "# Use the retrained model if it exists, otherwise, use the original model\n",
    "try:\n",
    "    model = xgb_retrained\n",
    "except NameError:\n",
    "    model = xgb\n",
    "\n",
    "# Create the transformer\n",
    "transformer = model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    strategy=\"MultiRecord\",\n",
    "    assemble_with=\"Line\",\n",
    "    accept=\"text/csv\",\n",
    "    output_path=\"s3://{}/{}/batch-transform/\".format(bucket, prefix)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run-batch-transform-job\n",
    "test_data_batch = test_data.drop(\"fraud\", axis=1)\n",
    "test_data_batch.to_csv(\"test_data_batch.csv\", index=False, header=False)\n",
    "test_path_batch = S3Uploader.upload(\"test_data_batch.csv\", \"s3://{}/{}\".format(bucket, prefix))\n",
    "\n",
    "transformer.transform(test_path_batch, content_type=\"text/csv\", split_type=\"Line\", join_source=\"Input\")\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue this lab, return to <a href=\"#task5-1-continue\" target=\"_self\">Task 5.1</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task5-2\" id=\"task5-2\"></a>\n",
    "\n",
    "### Appendix: View prediction and accuracy data from a batch transform job (Task 5.2)\n",
    "\n",
    "When your batch transform job is finished, view the prediction data stored in Amazon S3. You can reference the output path that you set up in the **transformer** and sample the data.\n",
    "\n",
    "In this output, the **fraud** prediction is appended to the end of each record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $transformer.output_path ./\n",
    "test_data = pd.read_csv(\"test_data_batch.csv.out\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue this lab, return to <a href=\"#task5-2-continue\" target=\"_self\">Task 5.2</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task5-3\" id=\"task5-3\"></a>\n",
    "\n",
    "### Appendix: Clean up SageMaker instances in SageMaker Studio (Task 5.3)\n",
    "\n",
    "While developing models in SageMaker Studio, periodically check if there are any instances that you want to clean up. If there are, you can shut down instances from within SageMaker Studio.\n",
    "\n",
    "1. In the left menu bar, choose the **Running Terminals and Kernels** icon (circle with a square in the middle).\n",
    "\n",
    "1. If there are any instances that are still open, to the right of each instance type, chose the **Shut down** icon. \n",
    "\n",
    "You can view the applications that are running on each instance to confirm which ones you want to close.\n",
    "\n",
    "1. If a popup window appears, choose **Shut down all**.\n",
    "\n",
    "1. Choose the **Refresh List** icon periodically until the instance is no longer on the list. It might take 25 minutes for an instance to shut down.\n",
    "\n",
    "You do not need to shut down the instance that your **capstone.ipynb** notebook is using.\n",
    "\n",
    "To continue this lab, return to <a href=\"#task5-3-continue\" target=\"_self\">Task 5.3</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task6-1\" id=\"task6-1\"></a>\n",
    "\n",
    "### Appendix: Configure a pipeline (Task 6.1)\n",
    "\n",
    "To create a pipeline, define each step of the pipeline process and then run it.\n",
    "\n",
    "In this example, you create the following steps:\n",
    "- **AutoModelProcess**: A **Processing** step that pulls in the .csv file and splits it into train, test, and validation datasets.\n",
    "- **AutoHyperParameterTuning**: A **Tuning** step that takes a range of hyperparameters and tunes the model.\n",
    "- **AutoEvalBestModel**: A **Processing** step that creates an evaluation report to describe the best model.\n",
    "- **CheckAUCScoreAutoEvaluation**: A **Condition** step that evaluates the models based on an evaluation metric. \n",
    "- **AutoCreateModel**: A **Model** step that creates a model.\n",
    "- **RegisterAutoModel-RegisterModel**: A **RegisterModel** step that registers a model.\n",
    "- **AutoModelConfigFile**: A **Processing** step that creates a bias report.\n",
    "- **AutoTransform**: A **Transform** step that runs a batch transform job.\n",
    "- **ClarifyProcessingStep**: A **Processing** step that runs a SageMaker Clarify job.\n",
    "\n",
    "If you get stuck at any point while building the pipeline, you can customize the following code or use it as a guide while you build your own pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run-pipeline\n",
    "# Set the variables\n",
    "model_name = \"Auto-model\"\n",
    "sklearn_processor_version=\"0.23-1\"\n",
    "model_package_group_name=\"AutoModelPackageGroup\"\n",
    "pipeline_name= \"AutoModelSMPipeline\"\n",
    "clarify_image = sagemaker.image_uris.retrieve(framework='sklearn',version=sklearn_processor_version,region=region)\n",
    "\n",
    "# Upload files to the default S3 bucket\n",
    "s3_client.put_object(Bucket=bucket,Key='data/')\n",
    "s3_client.put_object(Bucket=bucket,Key='input/code/')\n",
    "s3_client.upload_file(Filename=\"data/batch_data.csv\", Bucket=bucket, Key=\"data/batch_data.csv\")  #If you edit this, make sure to also edit the headers listed in generate_config to match your column names.\n",
    "s3_client.upload_file(Filename=\"data/claims_customer.csv\", Bucket=bucket, Key=\"data/claims_customer.csv\")  #If you edit this, make sure to also edit the headers listed in generate_config to match your column names.\n",
    "s3_client.upload_file(Filename=\"pipelines/evaluate.py\", Bucket=bucket, Key=\"input/code/evaluate.py\")\n",
    "s3_client.upload_file(Filename=\"pipelines/generate_config.py\", Bucket=bucket, Key=\"input/code/generate_config.py\")\n",
    "s3_client.upload_file(Filename=\"pipelines/preprocess.py\", Bucket=bucket, Key=\"input/code/preprocess.py\")\n",
    "\n",
    "# Configure important settings. Change the input_data if you want to\n",
    "# use a file other than the claims_customer.csv and batch_data.csv files.\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "processing_instance_type = ParameterString(\n",
    "        name=\"ProcessingInstanceType\",\n",
    "        default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "training_instance_type = ParameterString(\n",
    "        name=\"TrainingInstanceType\",\n",
    "        default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "input_data = ParameterString(\n",
    "        name=\"InputData\",\n",
    "        default_value=\"s3://{}/data/claims_customer.csv\".format(bucket), \n",
    ")\n",
    "batch_data = ParameterString(\n",
    "        name=\"BatchData\",\n",
    "        default_value=\"s3://{}/data/batch_data.csv\".format(bucket),\n",
    ")\n",
    "\n",
    "# Run a scikit-learn script to do data processing on SageMaker using \n",
    "# using the SKLearnProcessor class\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "        framework_version=sklearn_processor_version,\n",
    "        instance_type=processing_instance_type.default_value, \n",
    "        instance_count=processing_instance_count,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        role=role,\n",
    ")\n",
    "\n",
    "# Configure the processing step to pull in the input_data\n",
    "step_process = ProcessingStep(\n",
    "        name=\"AutoModelProcess\",\n",
    "        processor=sklearn_processor,\n",
    "        outputs=[\n",
    "            ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\",\\\n",
    "                             destination=f\"s3://{bucket}/output/train\" ),\n",
    "            ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\",\\\n",
    "                            destination=f\"s3://{bucket}/output/validation\"),\n",
    "            ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\",\\\n",
    "                            destination=f\"s3://{bucket}/output/test\"),\n",
    "            ProcessingOutput(output_name=\"batch\", source=\"/opt/ml/processing/batch\",\\\n",
    "                            destination=f\"s3://{bucket}/data/batch\"),\n",
    "            ProcessingOutput(output_name=\"baseline\", source=\"/opt/ml/processing/baseline\",\\\n",
    "                            destination=f\"s3://{bucket}/input/baseline\")\n",
    "        ],\n",
    "        code=f\"s3://{bucket}/input/code/preprocess.py\",\n",
    "        job_arguments=[\"--input-data\", input_data],\n",
    ")\n",
    "\n",
    "# Set up the model path, image uri, and hyperparameters for the estimator\n",
    "model_path = f\"s3://{bucket}/output\"\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.5-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=training_instance_type.default_value,\n",
    ")\n",
    "\n",
    "fixed_hyperparameters = {\n",
    "    \"eval_metric\":\"auc\",\n",
    "    \"objective\":\"binary:logistic\",\n",
    "    \"num_round\":\"100\",\n",
    "    \"rate_drop\":\"0.3\",\n",
    "    \"tweedie_variance_power\":\"1.4\"\n",
    "}\n",
    "\n",
    "xgb_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    hyperparameters=fixed_hyperparameters,\n",
    "    output_path=model_path,\n",
    "    base_job_name=f\"auto-train\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "# Set the hyperparameter ranges for the tuning step and configure the tuning step\n",
    "hyperparameter_ranges = {\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "    \"min_child_weight\": ContinuousParameter(1, 10),\n",
    "    \"alpha\": ContinuousParameter(0, 2),\n",
    "    \"max_depth\": IntegerParameter(1, 4),\n",
    "}\n",
    "objective_metric_name = \"validation:auc\"\n",
    "\n",
    "step_tuning = TuningStep(\n",
    "    name = \"AutoHyperParameterTuning\",\n",
    "    tuner = HyperparameterTuner(xgb_train, objective_metric_name, hyperparameter_ranges, max_jobs=2, max_parallel_jobs=2),\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    },\n",
    ")\n",
    "\n",
    "# Configure the processing step for evaluation\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"script-auto-eval\",\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"AutoEvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\",\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"AutoEvalBestModel\",\n",
    "    processor=script_eval,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_tuning.get_top_model_s3_uri(top_k=0,s3_bucket=bucket,prefix=\"output\"),\n",
    "            destination=\"/opt/ml/processing/model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"test\"\n",
    "            ].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\",\\\n",
    "                            destination=f\"s3://{bucket}/output/evaluation\"),\n",
    "    ],\n",
    "    code=f\"s3://{bucket}/input/code/evaluate.py\",\n",
    "    property_files=[evaluation_report],\n",
    ")\n",
    "\n",
    "# Configure model creation\n",
    "model = Model(\n",
    "    image_uri=image_uri,        \n",
    "    model_data=step_tuning.get_top_model_s3_uri(top_k=0,s3_bucket=bucket,prefix=\"output\"),\n",
    "    name=model_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "inputs = CreateModelInput(\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    accelerator_type=\"ml.inf1.xlarge\",\n",
    ")\n",
    "\n",
    "step_create_model = CreateModelStep(\n",
    "    name=\"AutoCreateModel\",\n",
    "    model=model,\n",
    "    inputs=inputs,\n",
    ")\n",
    "\n",
    "script_processor = ScriptProcessor(\n",
    "    command=['python3'],\n",
    "    image_uri=clarify_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=processing_instance_type,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "bias_report_output_path = f\"s3://{bucket}/clarify-output/bias\"\n",
    "clarify_instance_type = 'ml.m5.xlarge'\n",
    "step_config_file = ProcessingStep(\n",
    "    name=\"AutoModelConfigFile\",\n",
    "    processor=script_processor,\n",
    "    code=f\"s3://{bucket}/input/code/generate_config.py\",\n",
    "    job_arguments=[\"--modelname\",step_create_model.properties.ModelName,\"--bias-report-output-path\",bias_report_output_path,\"--clarify-instance-type\",clarify_instance_type,\\\n",
    "                  \"--default-bucket\",bucket,\"--num-baseline-samples\",\"50\",\"--instance-count\",\"1\"],\n",
    "    depends_on= [step_create_model.name]\n",
    ")\n",
    "\n",
    "# Configure the step to perform a batch transform job\n",
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    assemble_with=\"Line\",\n",
    "    accept=\"text/csv\",    \n",
    "    output_path=f\"s3://{bucket}/AutoTransform\"\n",
    ")\n",
    "\n",
    "step_transform = TransformStep(\n",
    "    name=\"AutoTransform\",\n",
    "    transformer=transformer,\n",
    "    inputs=TransformInput(data=batch_data,content_type=\"text/csv\",join_source=\"Input\",split_type=\"Line\")\n",
    ")\n",
    "\n",
    "# Configure the SageMaker Clarify processing step\n",
    "analysis_config_path = f\"s3://{bucket}/clarify-output/bias/analysis_config.json\"\n",
    "\n",
    "data_config = sagemaker.clarify.DataConfig(\n",
    "    s3_data_input_path=f's3://{bucket}/output/train/train.csv', \n",
    "    s3_output_path=bias_report_output_path,\n",
    "    label=0,\n",
    "    headers=list(pd.read_csv(\"./data/claims_customer.csv\", index_col=None).columns), #If you edit this, make sure to also edit the headers listed in generate_config to match your column names.\n",
    "    dataset_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "clarify_processor = sagemaker.clarify.SageMakerClarifyProcessor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=clarify_instance_type,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "config_input = ProcessingInput(\n",
    "    input_name=\"analysis_config\",\n",
    "    source=analysis_config_path,\n",
    "    destination=\"/opt/ml/processing/input/analysis_config\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    s3_input_mode=\"File\",\n",
    "    s3_compression_type=\"None\",\n",
    ")\n",
    "\n",
    "data_input = ProcessingInput(\n",
    "    input_name=\"dataset\",\n",
    "    source=data_config.s3_data_input_path,\n",
    "    destination=\"/opt/ml/processing/input/data\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    s3_input_mode=\"File\",\n",
    "    s3_data_distribution_type=data_config.s3_data_distribution_type,\n",
    "    s3_compression_type=data_config.s3_compression_type,\n",
    ")\n",
    "\n",
    "result_output = ProcessingOutput(\n",
    "    source=\"/opt/ml/processing/output\",\n",
    "    destination=data_config.s3_output_path,\n",
    "    output_name=\"analysis_result\",\n",
    "    s3_upload_mode=\"EndOfJob\",\n",
    ")\n",
    "\n",
    "step_clarify = ProcessingStep(\n",
    "    name=\"ClarifyProcessingStep\",\n",
    "    processor=clarify_processor,\n",
    "    inputs= [data_input, config_input],\n",
    "    outputs=[result_output],\n",
    "    depends_on = [step_config_file.name]\n",
    ")\n",
    "\n",
    "# Configure the model registration step\n",
    "model_statistics = MetricsSource(\n",
    "    s3_uri=\"s3://{}/output/evaluation/evaluation.json\".format(bucket),\n",
    "    content_type=\"application/json\"\n",
    ")\n",
    "explainability = MetricsSource(\n",
    "    s3_uri=\"s3://{}/clarify-output/bias/analysis.json\".format(bucket),\n",
    "    content_type=\"application/json\"\n",
    ")\n",
    "\n",
    "bias = MetricsSource(\n",
    "    s3_uri=\"s3://{}/clarify-output/bias/analysis.json\".format(bucket),\n",
    "    content_type=\"application/json\"\n",
    ") \n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=model_statistics,\n",
    "    explainability=explainability,\n",
    "    bias=bias\n",
    ")\n",
    "\n",
    "step_register = RegisterModel(\n",
    "    name=\"RegisterAutoModel\",\n",
    "    estimator=xgb_train,\n",
    "    model_data=step_tuning.get_top_model_s3_uri(top_k=0,s3_bucket=bucket,prefix=\"output\"),\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    model_metrics=model_metrics,\n",
    ")\n",
    "\n",
    "# Create the model evaluation step\n",
    "cond_lte = ConditionGreaterThan(\n",
    "    left=JsonGet(\n",
    "        step=step_eval,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"binary_classification_metrics.auc.value\"\n",
    "    ),\n",
    "    right=0.75,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"CheckAUCScoreAutoEvaluation\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_create_model,step_config_file,step_transform,step_clarify,step_register],\n",
    "    else_steps=[],\n",
    ")\n",
    "\n",
    "# Define the pipeline\n",
    "def get_pipeline(\n",
    "    region,\n",
    "    role=None,\n",
    "    default_bucket=None,\n",
    "    model_package_group_name=\"AutoModelPackageGroup\",\n",
    "    pipeline_name=\"AutoModelPipeline\",\n",
    "    base_prefix = None,\n",
    "    custom_image_uri = None,\n",
    "    sklearn_processor_version=None\n",
    "    ):\n",
    "    \"\"\"Gets a SageMaker ML Pipeline instance working with auto data.\n",
    "    Args:\n",
    "        region: AWS region to create and run the pipeline.\n",
    "        role: IAM role to create and run steps and pipeline.\n",
    "        default_bucket: the bucket to use for storing the artifacts\n",
    "    Returns:\n",
    "        an instance of a pipeline\n",
    "    \"\"\"\n",
    "\n",
    "    # pipeline instance\n",
    "    pipeline = Pipeline(\n",
    "        name=pipeline_name,\n",
    "        parameters=[\n",
    "            processing_instance_type,\n",
    "            processing_instance_count,\n",
    "            training_instance_type,\n",
    "            input_data,\n",
    "            batch_data,\n",
    "        ],\n",
    "        steps=[step_process,step_tuning,step_eval,step_cond],\n",
    "        sagemaker_session=sagemaker_session\n",
    "    )\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = get_pipeline(\n",
    "    region = region,\n",
    "    role=role,\n",
    "    default_bucket=bucket,\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    pipeline_name=pipeline_name,\n",
    "    custom_image_uri=clarify_image,\n",
    "    sklearn_processor_version=sklearn_processor_version\n",
    ")\n",
    "\n",
    "pipeline.upsert(role_arn=role)\n",
    "\n",
    "# Run the pipeline\n",
    "RunPipeline = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue this lab, return to <a href=\"#task6-1-continue\" target=\"_self\">Task 6.1</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task6-2\" id=\"task6-2\"></a>\n",
    "\n",
    "### Appendix: Monitor a pipeline (Task 6.2)\n",
    "\n",
    "Now that you have created and run the pipeline, monitor the pipeline. You can view the pipeline status in SageMaker Studio.\n",
    "\n",
    "If you want to delete the pipeline, you can remove it using **delete_pipeline**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe-pipeline\n",
    "RunPipeline.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list-pipeline-steps\n",
    "RunPipeline.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove-pipeline\n",
    "response = sagemaker_session.boto_session.client(\"sagemaker\", region_name=region).delete_pipeline(PipelineName='AutoModelSMPipeline')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue this lab, return to <a href=\"#task6-2-continue\" target=\"_self\">Task 6.2</a>."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "741de909edea0d5644898c592544ed98bede62b404d20772e5c4abc3c2f12566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
